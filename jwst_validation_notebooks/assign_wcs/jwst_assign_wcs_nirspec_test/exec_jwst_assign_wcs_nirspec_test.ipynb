{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Testing Notebook: NIRSpec, spec2, assign_wcs step\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: NIRSpec \n",
    "\n",
    "Tested on CV3 data\n",
    "\n",
    "### Table of Contents\n",
    "<div style=\"text-align: left\"> \n",
    "\n",
    "<br> [Imports](#imports_ID) <br> [Introduction](#intro_ID) <br> [Testing Data Set](#data_ID) <br> [Run the JWST pipeline and assign_wcs validation tests](#pipeline_ID): [FS Full-Frame test](#FULLFRAME), [FS ALLSLITS test](#ALLSLITS), [MOS test](#MOS), [IFU test](#IFU) <br> [About This Notebook](#about_ID)<br> [Results](#results) <br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T16:24:33.649875Z",
     "iopub.status.busy": "2022-09-20T16:24:33.648981Z",
     "iopub.status.idle": "2022-09-20T16:24:33.657244Z",
     "shell.execute_reply": "2022-09-20T16:24:33.656742Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "import shutil\n",
    "data_dir = TemporaryDirectory()\n",
    "\n",
    "os.chdir(data_dir.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T16:24:33.660575Z",
     "iopub.status.busy": "2022-09-20T16:24:33.660102Z",
     "iopub.status.idle": "2022-09-20T16:24:33.665865Z",
     "shell.execute_reply": "2022-09-20T16:24:33.665378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRDS cache location: /tmp/crds_cache\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if 'CRDS_CACHE_TYPE' in os.environ:\n",
    "    if os.environ['CRDS_CACHE_TYPE'] == 'local':\n",
    "        os.environ['CRDS_PATH'] = os.path.join(os.environ['HOME'], 'crds', 'cache')\n",
    "    elif os.path.isdir(os.environ['CRDS_CACHE_TYPE']):\n",
    "        os.environ['CRDS_PATH'] = os.environ['CRDS_CACHE_TYPE']\n",
    "print('CRDS cache location: {}'.format(os.environ['CRDS_PATH']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports_ID\"></a>\n",
    "# Imports\n",
    "The library imports relevant to this notebook are aready taken care of by importing PTT.\n",
    "\n",
    "* astropy.io for opening fits files\n",
    "* jwst.module.PipelineStep is the pipeline step being tested\n",
    "* matplotlib.pyplot.plt to generate plot\n",
    "\n",
    "NOTE: This notebook assumes that the pipeline version to be tested is already installed and its environment is activated.\n",
    "\n",
    "To be able to run this notebook you need to install nptt. \n",
    "\n",
    "If all goes well you will be able to import PTT.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T16:24:33.669870Z",
     "iopub.status.busy": "2022-09-20T16:24:33.669102Z",
     "iopub.status.idle": "2022-09-20T16:24:36.132471Z",
     "shell.execute_reply": "2022-09-20T16:24:36.131559Z"
    },
    "nbpresent": {
     "id": "45177853-942e-4949-9e30-f544d70ef5f4"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 16\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjwst\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massign_wcs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massign_wcs_step\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AssignWcsStep\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# The latest version of NPTT is installed in the requirements text file at:\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# /jwst_validation_notebooks/environment.yml\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# import NPTT\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnirspec_pipe_testing_tool\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnptt\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# To get data from Artifactory\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mci_watson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martifactory_helpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_bigdata\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/nirspec_pipe_testing_tool/__init__.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m DistributionNotFound:\n\u001b[1;32m      6\u001b[0m     __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m calwebb_spec2_pytests\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/nirspec_pipe_testing_tool/utils/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m change_filter_opaque2science\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m change_keywd\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m crm2STpipeline\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#from . import ESAsim_erm2crm\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#from . import ESAsim_post_processing\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fix_pointing\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/nirspec_pipe_testing_tool/utils/crm2STpipeline.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# import the modules needed within our tool\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m move_data2ext1\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m level2b_hdr_keywd_check \u001b[38;5;28;01mas\u001b[39;00m lev2bcheck\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m level2b_hdr_keywd_dict_map2sim \u001b[38;5;28;01mas\u001b[39;00m map2sim\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03mThis script is a wrapper for the 2 scripts needed to convert the ESA simulations in CRM to ST pipeline to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/nirspec_pipe_testing_tool/utils/level2b_hdr_keywd_check.py:57\u001b[0m\n\u001b[1;32m     55\u001b[0m wit4_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWIT4_PATH\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     56\u001b[0m nirspec_cdp3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnirspec/CDP3/03_Instrument_model/3.1_Files/NIRS_FM2_05_CV3_FIT1/Description\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 57\u001b[0m path_to_tilt_files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwit4_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnirspec_cdp3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# General functions\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_hdrfits\u001b[39m(fits_file_name):\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/posixpath.py:76\u001b[0m, in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin\u001b[39m(a, \u001b[38;5;241m*\u001b[39mp):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;124;03m\"\"\"Join two or more pathname components, inserting '/' as needed.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    If any component is an absolute path, all previous path components\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    will be discarded.  An empty last part will result in a path that\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    ends with a separator.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     sep \u001b[38;5;241m=\u001b[39m _get_sep(a)\n\u001b[1;32m     78\u001b[0m     path \u001b[38;5;241m=\u001b[39m a\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import psutil\n",
    "from astropy.io import fits\n",
    "\n",
    "# Only print a DeprecationWarning the first time it shows up, not every time.\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"once\", category=DeprecationWarning)\n",
    "    import jwst\n",
    "    from jwst.pipeline.calwebb_detector1 import Detector1Pipeline\n",
    "    from jwst.assign_wcs.assign_wcs_step import AssignWcsStep\n",
    "\n",
    "# The latest version of NPTT is installed in the requirements text file at:\n",
    "# /jwst_validation_notebooks/environment.yml\n",
    "\n",
    "# import NPTT\n",
    "import nirspec_pipe_testing_tool as nptt\n",
    "\n",
    "# To get data from Artifactory\n",
    "from ci_watson.artifactory_helpers import get_bigdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the version used is the right one\n",
    "\n",
    "pipeline_version = jwst.__version__\n",
    "nptt_version = nptt.__version__\n",
    "\n",
    "print(\"Using jwst pipeline version: \", pipeline_version)\n",
    "print(\"Using NPTT version: \", nptt_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro_ID\"></a>\n",
    "# Test Description\n",
    "\n",
    "We compared Institute's pipeline product of the assign_wcs step with our benchmark files, or with the intermediary products from the ESA pipeline, which is completely independent from the Institute's. The comparison file is referred to as 'truth'. We calculated the relative difference and expected it to be equal to or less than computer precision:  relative_difference = absolute_value( (Truth - ST)/Truth )  <= 1x10^-7. \n",
    "\n",
    "For the test to be considered PASSED, every single slit (for FS data), slitlet (for MOS data) or slice (for IFU data) in the input file has to pass. If there is any failure, the whole test will be considered as FAILED. \n",
    "\n",
    "The code for this test for Fixed Slits (FS) can be obtained from: https://github.com/spacetelescope/nirspec_pipe_testing_tool/blob/master/nirspec_pipe_testing_tool/calwebb_spec2_pytests/auxiliary_code/compare_wcs_fs.py. For Multi Object Spectroscopy (MOS), the code is in the same repository but is named ```compare_wcs_mos.py```, and for Integral Field Unit (IFU) data, the test is named ```compare_wcs_ifu.py```.\n",
    "The input file is defined in the variable ```input_file``` (see section [Testing Data Set and Variable Setup](#data_ID)).\n",
    "\n",
    "Step description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/assign_wcs/main.html\n",
    "\n",
    "Pipeline code: https://github.com/spacetelescope/jwst/tree/master/jwst/assign_wcs\n",
    "\n",
    "\n",
    "### Results\n",
    "\n",
    "If the test **PASSED** this means that all slits, slitlets, or slices individually passed the test. However, if ony one individual slit (for FS data), slitlet (for MOS data) or slice (for IFU data) test failed, the whole test will be reported as **FAILED**.### Calibration WG Requested Algorithm: \n",
    "\n",
    "\n",
    "### Calibration WG Requested Algorithm: \n",
    "\n",
    "A short description and link to the page: https://outerspace.stsci.edu/display/JWSTCC/Vanilla+Spectral+GWCS+Information \n",
    "\n",
    "\n",
    "### Defining Term\n",
    "Acronymns used un this notebook:\n",
    "\n",
    "pipeline: calibration pipeline\n",
    "\n",
    "spec2: spectroscopic calibration pipeline level 2b\n",
    "\n",
    "PTT: NIRSpec pipeline testing tool (https://github.com/spacetelescope/nirspec_pipe_testing_tool)\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline_ID\"></a>\n",
    "# Run the JWST pipeline and assign_wcs validation tests\n",
    "\n",
    "The pipeline can be run from the command line in two variants: full or per step.\n",
    "\n",
    "Tu run the spec2 pipeline in full use the command: \n",
    "\n",
    "$ strun jwst.pipeline.Spec2Pipeline jwtest_rate.fits\n",
    "\n",
    "Tu only run the assign_wcs step, use the command:\n",
    "\n",
    "$ strun jwst.assign_wcs.AssignWcsStep jwtest_rate.fits\n",
    "\n",
    "NIRSpec TA data will be run through the cal_detector1 and the imaging2 pipelines. The imaging pipeline can be run with the following fommand:\n",
    "\n",
    "$ strun jwst.pipeline.Image2Pipeline jwtest_rate.fits\n",
    "\n",
    "These options are also callable from a script with the testing environment active. The Python call for running the pipeline in full or by step are:\n",
    "\n",
    "$\\gt$ from jwst.pipeline.calwebb_spec2 import Spec2Pipeline\n",
    "\n",
    "$\\gt$ Spec2Pipeline.call(jwtest_rate.fits)\n",
    " \n",
    "or\n",
    " \n",
    "$\\gt$ from jwst.assign_wcs.assign_wcs_step import AssignWcsStep\n",
    " \n",
    "$\\gt$ AssignWcsStep.call(jwtest_rate.fits)\n",
    "\n",
    "For the imaging pipeline the call would be as follows:\n",
    "\n",
    "$\\gt$ from jwst.pipeline.calwebb_image2 import Image2Pipeline\n",
    "\n",
    "$\\gt$ Image2Pipeline.call(jwtest_rate.fits)\n",
    "\n",
    "NPTT can run the spec2 pipeline either in full or per step, as well as the imaging pipeline in full. In this notebook we will use NPTT to run the pipeline and the validation tests. To run NPTT, follow the directions in the corresponding repo page.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_ID\"></a>\n",
    "# Testing Data Set\n",
    "\n",
    "All testing data is from the CV3 campaign. We chose these files because this is our most complete data set, i.e. all modes and filter-grating combinations.\n",
    "\n",
    "Data used was for testing:\n",
    "- FS_PRISM_CLEAR\n",
    "- FS_FULLFRAME_G395H_F290LP\n",
    "- FS_ALLSLITS_G140H_F100LP \n",
    "- MOS_G140M_LINE1 \n",
    "- MOS_PRISM_CLEAR\n",
    "- IFU_G395H_F290LP \n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = {'fs_prism_clear':{\n",
    "                                  'uncal_file_nrs1': 'fs_prism_nrs1_uncal.fits',\n",
    "                                  'uncal_file_nrs2': 'fs_prism_nrs2_uncal.fits',\n",
    "                                  'truth_file_nrs1': 'fs_prism_nrs1_assign_wcs_truth.fits',\n",
    "                                  'truth_file_nrs2': 'fs_prism_nrs2_assign_wcs_truth.fits',\n",
    "                                  'msa_shutter_config': None },\n",
    "                \n",
    "                'fs_fullframe_g395h_f290lp':{\n",
    "                                  'uncal_file_nrs1': 'fs_fullframe_g395h_f290lp_nrs1_uncal.fits',\n",
    "                                  'uncal_file_nrs2': 'fs_fullframe_g395h_f290lp_nrs2_uncal.fits',\n",
    "                                  'truth_file_nrs1': 'fs_fullframe_g395h_f290lp_nrs1_assign_wcs_truth.fits',\n",
    "                                  'truth_file_nrs2': 'fs_fullframe_g395h_f290lp_nrs2_assign_wcs_truth.fits',  \n",
    "                                  'msa_shutter_config': None },\n",
    "                \n",
    "                'fs_allslits_g140h_f100lp':{\n",
    "                                  'uncal_file_nrs1': 'fs_allslits_g140h_f100lp_nrs1_uncal.fits',\n",
    "                                  'uncal_file_nrs2': 'fs_allslits_g140h_f100lp_nrs2_uncal.fits',\n",
    "                                  'truth_file_nrs1': 'fs_allslits_g140h_f100lp_nrs1_assign_wcs_truth.fits',\n",
    "                                  'truth_file_nrs2': 'fs_allslits_g140h_f100lp_nrs2_assign_wcs_truth.fits',\n",
    "                                  'msa_shutter_config': None },\n",
    "                \n",
    "                'bots_g235h_f170lp':{\n",
    "                                  'uncal_file_nrs1': 'bots_g235h_f170lp_nrs1_uncal.fits',\n",
    "                                  'uncal_file_nrs2': 'bots_g235h_f170lp_nrs2_uncal.fits',\n",
    "                                  'truth_file_nrs1': 'bots_g235h_f170lp_nrs1_assign_wcs_truth.fits',\n",
    "                                  'truth_file_nrs2': 'bots_g235h_f170lp_nrs2_assign_wcs_truth.fits',\n",
    "                                  'msa_shutter_config': None },\n",
    "                \n",
    "                'mos_prism_clear':{\n",
    "                                  'uncal_file_nrs1': 'mos_prism_nrs1_uncal.fits',\n",
    "                                  'uncal_file_nrs2': 'mos_prism_nrs2_uncal.fits',\n",
    "                                  'truth_file_nrs1': 'mos_prism_nrs1_assign_wcs_truth.fits',\n",
    "                                  'truth_file_nrs2': None,\n",
    "                                  'msa_shutter_config': 'V0030006000104_msa.fits' },\n",
    "                \n",
    "                'mos_g140m_f100lp':{\n",
    "                                  'uncal_file_nrs1': 'mos_g140m_f100lp_nrs1_uncal.fits',\n",
    "                                  'uncal_file_nrs2': 'mos_g140m_f100lp_nrs2_uncal.fits',  \n",
    "                                  'truth_file_nrs1': 'mos_g140m_f100lp_nrs1_assign_wcs_truth.fits',\n",
    "                                  'truth_file_nrs2': 'mos_g140m_f100lp_nrs2_assign_wcs_truth.fits',\n",
    "                                  'msa_shutter_config': 'V8460001000101_msa.fits' },\n",
    "                \n",
    "                'ifu_prism_clear':{\n",
    "                                  'uncal_file_nrs1': 'ifu_prism_nrs1_uncal.fits',\n",
    "                                  'uncal_file_nrs2': 'ifu_prism_nrs2_uncal.fits',\n",
    "                                  'truth_file_nrs1': 'ifu_prism_nrs1_assign_wcs_truth.fits',\n",
    "                                  'truth_file_nrs2': None,\n",
    "                                  'msa_shutter_config': None },\n",
    "               \n",
    "                'ifu_g395h_f290lp':{\n",
    "                                  'uncal_file_nrs1': 'ifu_g395h_f290lp_nrs1_uncal.fits',\n",
    "                                  'uncal_file_nrs2': 'ifu_g395h_f290lp_nrs2_uncal.fits',\n",
    "                                  'truth_file_nrs1': 'ifu_g395h_f290lp_nrs1_assign_wcs_truth.fits',\n",
    "                                  'truth_file_nrs2': 'ifu_g395h_f290lp_nrs2_assign_wcs_truth.fits',\n",
    "                                  'msa_shutter_config': None }\n",
    "\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to pull data from Artifactory\n",
    "def get_artifactory_file(data_set_dict, detector):\n",
    "    \"\"\"This function creates a list with all the files needed per detector to run the test.\n",
    "    Args:\n",
    "        data_set_dict: dictionary, contains inputs for a specific mode and configuration\n",
    "        detector: string, either nrs1 or nrs2\n",
    "    Returns:\n",
    "        data: list, contains all files needed to run test\n",
    "    \"\"\"\n",
    "    files2obtain = ['uncal_file_nrs1', 'truth_file_nrs1', 'msa_shutter_config']\n",
    "    data = []\n",
    "    for file in files2obtain:\n",
    "        data_file = None\n",
    "        try: \n",
    "            if '_nrs' in file and '2' in detector:\n",
    "                file = file.replace('_nrs1', '_nrs2')\n",
    "\n",
    "            data_file = get_bigdata('jwst_validation_notebooks',\n",
    "                                         'validation_data',\n",
    "                                         'nirspec_data', \n",
    "                                         data_set_dict[file])\n",
    "        except TypeError:\n",
    "            data.append(None)\n",
    "            continue\n",
    "\n",
    "        data.append(data_file)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set common NPTT switches for this test and run the test for both detectors for each data set\n",
    "\n",
    "# define benchmark (or 'truth') file\n",
    "compare_assign_wcs_and_extract_2d_with_esa = False\n",
    "\n",
    "# accepted threshold difference with respect to benchmark files\n",
    "threshold_diff = 1e-7\n",
    "\n",
    "# other variables\n",
    "esa_files_path, raw_data_root_file = None, None\n",
    "save_figs = False\n",
    "show_figs = True\n",
    "detectors = ['nrs1', 'nrs2']\n",
    "results_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the FS data for PRISM and FULLFRAME\n",
    "for mode_config, data_set_dict in testing_data.items():\n",
    "    if 'mos' in mode_config or 'ifu' in mode_config:\n",
    "        continue\n",
    "    if 'bots' in mode_config or 'allslits' in mode_config:\n",
    "        continue\n",
    "        \n",
    "    print('Fixed slit mode:  ', mode_config)\n",
    "    for det in detectors:\n",
    "        print('Testing files for detector: ', det)\n",
    "        data = get_artifactory_file(data_set_dict, det)\n",
    "        uncal_file, truth_file, msa_shutter_config = data\n",
    "        uncal_basename = os.path.basename(uncal_file)\n",
    "        print('Working with uncal_file: ', uncal_basename)\n",
    "        \n",
    "        # Make sure that there is an assign_wcs truth product to compare to, else skip this data set\n",
    "        if truth_file is None:\n",
    "            print('No truth file to compare to for this detector, skipping this data set.  \\n')\n",
    "            skip_file = True\n",
    "\n",
    "        # Make sure these keywords are properly set\n",
    "        filt = fits.getval(uncal_file, 'FILTER')\n",
    "        if 'OPAQUE' in filt or 'allslits' in uncal_basename.lower():\n",
    "            if 'clear' in uncal_basename.lower():\n",
    "                filt = 'CLEAR'\n",
    "            else:\n",
    "                l = uncal_basename.split(\"_\")\n",
    "                for li in l:\n",
    "                    if 'lp' in li:\n",
    "                        filt = li.upper()\n",
    "                        break\n",
    "            fits.setval(uncal_file, 'FILTER', value=filt)\n",
    "        print('Filter = ', filt)\n",
    "        if 'bots' in uncal_basename.lower():\n",
    "            fits.setval(uncal_file, 'TSOVISIT', value=True)\n",
    "            fits.setval(uncal_file, 'FXD_SLIT', value='S1600A1')\n",
    "        elif 'fs' in uncal_basename.lower():\n",
    "            fits.setval(uncal_file, 'FXD_SLIT', value='S200A1')\n",
    "\n",
    "        # Run the stage 1 pipeline \n",
    "        print('Running detector1 pipeline...')\n",
    "        rate_object = Detector1Pipeline.call(uncal_file)\n",
    "        \n",
    "        # Run the stage 2 pipeline steps\n",
    "        print('Running spec2 pipeline...')\n",
    "        try:\n",
    "            assign_wcs_object = AssignWcsStep.call(rate_object)\n",
    "            skip_file = False\n",
    "        except:\n",
    "            print(\"No open slits fall on detector \", det)\n",
    "            print(\"Skipping test for this file. \\n\")\n",
    "            skip_file = True\n",
    "            \n",
    "        if not skip_file:  \n",
    "            # Run the validation test\n",
    "            %matplotlib inline\n",
    "            print('Running test for FS...')\n",
    "            result, _ = nptt.calwebb_spec2_pytests.auxiliary_code.compare_wcs_fs.compare_wcs(\n",
    "                                                                            assign_wcs_object, \n",
    "                                                                            truth_file=truth_file, \n",
    "                                                                            esa_files_path=esa_files_path, \n",
    "                                                                            show_figs=show_figs,\n",
    "                                                                            save_figs=save_figs, \n",
    "                                                                            threshold_diff=threshold_diff, \n",
    "                                                                            raw_data_root_file=raw_data_root_file,\n",
    "                                                                            output_directory=None)     \n",
    "        else:\n",
    "            result = 'skipped'\n",
    "        \n",
    "        # Did the test passed \n",
    "        print(\"Did FS assign_wcs validation test passed? \", result, \"\\n\\n\")\n",
    "        rd = {uncal_basename: result}\n",
    "        results_dict.update(rd)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the FS data for ALLSLITS\n",
    "for mode_config, data_set_dict in testing_data.items():\n",
    "    if 'mos' in mode_config or 'ifu' in mode_config:\n",
    "        continue\n",
    "    if 'allslits' in mode_config:\n",
    "        continue\n",
    "        \n",
    "    print('Fixed slit mode:  ', mode_config)\n",
    "    for det in detectors:\n",
    "        print('Testing files for detector: ', det)\n",
    "        data = get_artifactory_file(data_set_dict, det)\n",
    "        uncal_file, truth_file, msa_shutter_config = data\n",
    "        uncal_basename = os.path.basename(uncal_file)\n",
    "        print('Working with uncal_file: ', uncal_basename)\n",
    "        \n",
    "        # Make sure that there is an assign_wcs truth product to compare to, else skip this data set\n",
    "        if truth_file is None:\n",
    "            print('No truth file to compare to for this detector, skipping this data set.  \\n')\n",
    "            skip_file = True\n",
    "\n",
    "        # Make sure these keywords are properly set\n",
    "        filt = fits.getval(uncal_file, 'FILTER')\n",
    "        if 'OPAQUE' in filt or 'allslits' in uncal_basename.lower():\n",
    "            if 'clear' in uncal_basename.lower():\n",
    "                filt = 'CLEAR'\n",
    "            else:\n",
    "                l = uncal_basename.split(\"_\")\n",
    "                for li in l:\n",
    "                    if 'lp' in li:\n",
    "                        filt = li.upper()\n",
    "                        break\n",
    "            fits.setval(uncal_file, 'FILTER', value=filt)\n",
    "        print('Filter = ', filt)\n",
    "        if 'bots' in uncal_basename.lower():\n",
    "            fits.setval(uncal_file, 'TSOVISIT', value=True)\n",
    "            fits.setval(uncal_file, 'FXD_SLIT', value='S1600A1')\n",
    "        elif 'fs' in uncal_basename.lower():\n",
    "            fits.setval(uncal_file, 'FXD_SLIT', value='S200A1')\n",
    "\n",
    "        # Run the stage 1 pipeline \n",
    "        print('Running detector1 pipeline...')\n",
    "        rate_object = Detector1Pipeline.call(uncal_file)\n",
    "        \n",
    "        # Run the stage 2 pipeline steps\n",
    "        print('Running spec2 pipeline...')\n",
    "        try:\n",
    "            assign_wcs_object = AssignWcsStep.call(rate_object)\n",
    "            skip_file = False\n",
    "        except:\n",
    "            print(\"No open slits fall on detector \", det)\n",
    "            print(\"Skipping test for this file. \\n\")\n",
    "            skip_file = True\n",
    "            \n",
    "        if not skip_file:  \n",
    "            # Run the validation test\n",
    "            %matplotlib inline\n",
    "            print('Running test for FS...')\n",
    "            result, _ = nptt.calwebb_spec2_pytests.auxiliary_code.compare_wcs_fs.compare_wcs(\n",
    "                                                                            assign_wcs_object, \n",
    "                                                                            truth_file=truth_file, \n",
    "                                                                            esa_files_path=esa_files_path, \n",
    "                                                                            show_figs=show_figs,\n",
    "                                                                            save_figs=save_figs, \n",
    "                                                                            threshold_diff=threshold_diff, \n",
    "                                                                            raw_data_root_file=raw_data_root_file,\n",
    "                                                                            output_directory=None)     \n",
    "        else:\n",
    "            result = 'skipped'\n",
    "        \n",
    "        # Did the test passed \n",
    "        print(\"Did FS assign_wcs validation test passed? \", result, \"\\n\\n\")\n",
    "        rd = {uncal_basename: result}\n",
    "        results_dict.update(rd)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the FS data for BOTS\n",
    "for mode_config, data_set_dict in testing_data.items():\n",
    "    if 'mos' in mode_config or 'ifu' in mode_config:\n",
    "        continue\n",
    "    if 'bots' not in mode_config:\n",
    "        continue\n",
    "        \n",
    "    print('Fixed slit mode:  ', mode_config)\n",
    "    for det in detectors:\n",
    "        print('Testing files for detector: ', det)\n",
    "        data = get_artifactory_file(data_set_dict, det)\n",
    "        uncal_file, truth_file, msa_shutter_config = data\n",
    "        uncal_basename = os.path.basename(uncal_file)\n",
    "        print('Working with uncal_file: ', uncal_basename)\n",
    "        \n",
    "        # Make sure that there is an assign_wcs truth product to compare to, else skip this data set\n",
    "        if truth_file is None:\n",
    "            print('No truth file to compare to for this detector, skipping this data set.  \\n')\n",
    "            skip_file = True\n",
    "\n",
    "        # Make sure these keywords are properly set\n",
    "        filt = fits.getval(uncal_file, 'FILTER')\n",
    "        if 'OPAQUE' in filt or 'allslits' in uncal_basename.lower():\n",
    "            if 'clear' in uncal_basename.lower():\n",
    "                filt = 'CLEAR'\n",
    "            else:\n",
    "                l = uncal_basename.split(\"_\")\n",
    "                for li in l:\n",
    "                    if 'lp' in li:\n",
    "                        filt = li.upper()\n",
    "                        break\n",
    "            fits.setval(uncal_file, 'FILTER', value=filt)\n",
    "        print('Filter = ', filt)\n",
    "        if 'bots' in uncal_basename.lower():\n",
    "            fits.setval(uncal_file, 'TSOVISIT', value=True)\n",
    "            fits.setval(uncal_file, 'FXD_SLIT', value='S1600A1')\n",
    "        elif 'fs' in uncal_basename.lower():\n",
    "            fits.setval(uncal_file, 'FXD_SLIT', value='S200A1')\n",
    "\n",
    "        # Run the stage 1 pipeline \n",
    "        print('Running detector1 pipeline...')\n",
    "        rate_object = Detector1Pipeline.call(uncal_file)\n",
    "        \n",
    "        # Run the stage 2 pipeline steps\n",
    "        print('Running spec2 pipeline...')\n",
    "        try:\n",
    "            assign_wcs_object = AssignWcsStep.call(rate_object)\n",
    "            skip_file = False\n",
    "        except:\n",
    "            print(\"No open slits fall on detector \", det)\n",
    "            print(\"Skipping test for this file. \\n\")\n",
    "            skip_file = True\n",
    "            \n",
    "        if not skip_file:  \n",
    "            # Run the validation test\n",
    "            %matplotlib inline\n",
    "            print('Running test for FS...')\n",
    "            result, _ = nptt.calwebb_spec2_pytests.auxiliary_code.compare_wcs_fs.compare_wcs(\n",
    "                                                                            assign_wcs_object, \n",
    "                                                                            truth_file=truth_file, \n",
    "                                                                            esa_files_path=esa_files_path, \n",
    "                                                                            show_figs=show_figs,\n",
    "                                                                            save_figs=save_figs, \n",
    "                                                                            threshold_diff=threshold_diff, \n",
    "                                                                            raw_data_root_file=raw_data_root_file,\n",
    "                                                                            output_directory=None)     \n",
    "        else:\n",
    "            result = 'skipped'\n",
    "        \n",
    "        # Did the test passed \n",
    "        print(\"Did FS assign_wcs validation test passed? \", result, \"\\n\\n\")\n",
    "        rd = {uncal_basename: result}\n",
    "        results_dict.update(rd)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the MOS data\n",
    "for mode_config, data_set_dict in testing_data.items():\n",
    "    if 'mos' not in mode_config:\n",
    "        continue\n",
    "        \n",
    "    print('MOS mode:  ', mode_config)\n",
    "    for det in detectors:\n",
    "        print('Testing files for detector: ', det)\n",
    "        data = get_artifactory_file(data_set_dict, det)\n",
    "        uncal_file, truth_file, msa_shutter_config = data\n",
    "        uncal_basename = os.path.basename(uncal_file)\n",
    "        print('Working with uncal_file: ', uncal_basename)\n",
    "        \n",
    "        # Make sure that there is an assign_wcs truth product to compare to, else skip this data set\n",
    "        if truth_file is None:\n",
    "            print('No truth file to compare to for this detector, skipping this data set.  \\n')\n",
    "            skip_file = True\n",
    "            \n",
    "        # Make sure these keywords are properly set\n",
    "        filt = fits.getval(uncal_file, 'FILTER')\n",
    "        if 'OPAQUE' in filt:\n",
    "            if 'clear' in uncal_basename.lower():\n",
    "                filt = 'CLEAR'\n",
    "            else:\n",
    "                l = uncal_basename.split(\"_\")\n",
    "                for li in l:\n",
    "                    if 'lp' in li:\n",
    "                        filt = li.upper()\n",
    "                        break\n",
    "            fits.setval(uncal_file, 'FILTER', value=filt)\n",
    "        print('Filter = ', filt)\n",
    "            \n",
    "        # Run the stage 1 pipeline \n",
    "        print('Running detector1 pipeline...')\n",
    "        rate_object = Detector1Pipeline.call(uncal_file)\n",
    "        \n",
    "        # Make sure the MSA shutter configuration file is set up correctly\n",
    "        if msa_shutter_config is not None:\n",
    "            msa_metadata = rate_object.meta.instrument.msa_metadata_file\n",
    "            if msa_metadata is None or msa_metadata == 'N/A':\n",
    "                rate_object.meta.instrument.msa_metadata_file = msa_shutter_config\n",
    "\n",
    "        # Run the stage 2 pipeline steps\n",
    "        print('Running spec2 pipeline...')\n",
    "        try:\n",
    "            assign_wcs_object = AssignWcsStep.call(rate_object)\n",
    "            skip_file = False\n",
    "        except:\n",
    "            print(\"No open slits fall on detector \", det)\n",
    "            print(\"Skipping test for this file. \\n\")\n",
    "            skip_file = True\n",
    "            \n",
    "        if not skip_file:  \n",
    "            # Run the validation test\n",
    "            %matplotlib inline\n",
    "            print('Running test for MOS...')\n",
    "            result, _ = nptt.calwebb_spec2_pytests.auxiliary_code.compare_wcs_mos.compare_wcs(\n",
    "                                                                            assign_wcs_object, \n",
    "                                                                            msa_conf_name=msa_shutter_config, \n",
    "                                                                            truth_file=truth_file,\n",
    "                                                                            esa_files_path=esa_files_path, \n",
    "                                                                            show_figs=show_figs, \n",
    "                                                                            save_figs=save_figs, \n",
    "                                                                            threshold_diff=threshold_diff,\n",
    "                                                                            mode_used='mos', \n",
    "                                                                            raw_data_root_file=raw_data_root_file)\n",
    "        else:\n",
    "            result = 'skipped'\n",
    "\n",
    "        # Did the test passed \n",
    "        print(\"Did MOS assign_wcs validation test passed? \", result, \"\\n\\n\")\n",
    "        rd = {uncal_basename: result}\n",
    "        results_dict.update(rd)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the IFU data\n",
    "for mode_config, data_set_dict in testing_data.items():\n",
    "    if 'ifu' not in mode_config:\n",
    "        continue\n",
    "        \n",
    "    print('IFU mode:  ', mode_config)\n",
    "    for det in detectors:\n",
    "        print('Testing files for detector: ', det)\n",
    "        data = get_artifactory_file(data_set_dict, det)\n",
    "        uncal_file, truth_file, msa_shutter_config = data\n",
    "        uncal_basename = os.path.basename(uncal_file)\n",
    "        print('Working with uncal_file: ', uncal_basename)\n",
    "        \n",
    "        # Make sure that there is an assign_wcs truth product to compare to, else skip this data set\n",
    "        if truth_file is None:\n",
    "            print('No truth file to compare to for this detector, skipping this data set.  \\n')\n",
    "            skip_file = True\n",
    "        \n",
    "        # Make sure these keywords are properly set\n",
    "        filt = fits.getval(uncal_file, 'FILTER')\n",
    "        if 'OPAQUE' in filt:\n",
    "            if 'clear' in uncal_basename.lower():\n",
    "                filt = 'CLEAR'\n",
    "            else:\n",
    "                l = uncal_basename.split(\"_\")\n",
    "                for li in l:\n",
    "                    if 'lp' in li:\n",
    "                        filt = li.upper()\n",
    "                        break\n",
    "            fits.setval(uncal_file, 'FILTER', value=filt)\n",
    "        print('Filter = ', filt)\n",
    "\n",
    "        # Run the stage 1 pipeline \n",
    "        print('Running detector1 pipeline...')\n",
    "        rate_object = Detector1Pipeline.call(uncal_file)\n",
    "        \n",
    "        # Run the stage 2 pipeline steps\n",
    "        print('Running spec2 pipeline')\n",
    "        try:\n",
    "            assign_wcs_object = AssignWcsStep.call(rate_object)\n",
    "            skip_file = False\n",
    "        except:\n",
    "            print(\"No open slits fall on detector \", det)\n",
    "            print(\"Skipping test for this file. \\n\")\n",
    "            skip_file = True\n",
    "            \n",
    "        if not skip_file:  \n",
    "            # Run the validation test\n",
    "            %matplotlib inline\n",
    "            print('Running test for IFU...')\n",
    "            result, _ = nptt.calwebb_spec2_pytests.auxiliary_code.compare_wcs_ifu.compare_wcs(\n",
    "                                                                            assign_wcs_object, \n",
    "                                                                            truth_file=truth_file, \n",
    "                                                                            esa_files_path=esa_files_path, \n",
    "                                                                            show_figs=show_figs,\n",
    "                                                                            save_figs=save_figs, \n",
    "                                                                            threshold_diff=threshold_diff, \n",
    "                                                                            raw_data_root_file=raw_data_root_file)\n",
    "        else:\n",
    "            result = 'skipped'\n",
    "\n",
    "        # Did the test passed \n",
    "        print(\"Did IFU assign_wcs validation test passed? \", result, \"\\n\\n\")\n",
    "        rd = {uncal_basename: result}\n",
    "        results_dict.update(rd)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of modes tested and their results \n",
    "\n",
    "print('These are the final results of the tests: ')\n",
    "for key, val in results_dict.items():\n",
    "    if not isinstance(val, str):\n",
    "        if val:\n",
    "            val = 'PASSED'\n",
    "        else:\n",
    "            val = 'FAILED'\n",
    "    print('{:<42} {:<8}'.format(key, val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about_ID\"></a>\n",
    "## About this Notebook\n",
    "**Author:** Maria A. Pena-Guerrero, Sr. Science Software Engineer, NIRSpec\n",
    "<br>**Updated On:** Mar/4/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)\n",
    "<img style=\"float: right;\" src=\"./stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"stsci_pri_combo_mark_horizonal_white_bkgd\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
