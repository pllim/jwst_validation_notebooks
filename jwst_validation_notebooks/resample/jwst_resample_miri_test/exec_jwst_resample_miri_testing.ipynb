{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Testing Notebook: Calwebb_Image3, Resample step with MIRI imaging\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: FGS, MIRI, NIRCam, NIRISS, NIRSpec \n",
    "\n",
    "Tested on MIRI Simulated data\n",
    "\n",
    "### Table of Contents\n",
    "<div style=\"text-align: left\"> \n",
    "\n",
    "<br>  [Introduction](#intro_ID) <br> [Run JWST Pipelines](#pipeline_ID) <br> [Imports](#imports_ID) <br> [Create an association table for your cal files and run them through calwebb_image3](#runpipeline_ID) <br> [Find Stars in Image and Determine their Coordinates](#runscript_ID) <br> [Compare RA and Dec to expected Values](#residual_ID) <br> [About This Notebook](#about_ID) <br>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro_ID\"></a>\n",
    "# Introduction\n",
    "\n",
    "\n",
    "This test is designed to test the resample step in the calwebb_image3 pipeline. At the end of the calwebb_image3 pipeline, the set of files defined in an association table will be distortion corrected and combined. Resample is the step that applies the distortion correction using the drizzling algorithm (as defined in the DrizzlePac handbook) and combines the listed files. For more information on the pipeline step visit the links below. \n",
    "\n",
    "Step description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/resample/main.html\n",
    "\n",
    "Pipeline code: https://github.com/spacetelescope/jwst/tree/master/jwst/resample\n",
    "\n",
    "The data for this test were created with the MIRI Data Simulator, and the documentation for that code can be found here: http://miri.ster.kuleuven.be/bin/view/Public/MIRISim_Public\n",
    "\n",
    "\n",
    "### Calibration WG Requested Algorithm: \n",
    "\n",
    "A short description and link to the page: https://outerspace.stsci.edu/display/JWSTCC/Vanilla+Image+Combination\n",
    "\n",
    "\n",
    "### Defining Terms\n",
    "Definition of terms or acronymns.\n",
    "\n",
    "JWST: James Webb Space Telescope\n",
    "\n",
    "MIRI: Mid-Infrared Instrument\n",
    "\n",
    "MIRISim: MIRI Data Simulator\n",
    "\n",
    "### Description of test\n",
    "\n",
    "This test is performed by creating a set of simulated data with multiple point sources located at specified coordinates. The simulator puts in the expected distortion, so the initial output data comes out of the simulator in distorted coordinates. When this data is then run through calwebb_detector1, calwebb_image2 and calwebbb_image3, the combined, undistorted image should have the point sources registered at the expected locations. In flight, this test can be repeated with known stars that should be found at their expected coordinates. This notebook also checks that flux values for simulated data with roughly equivalent input values show no systematic patterns after resampling. This portion of the test will only work with simulated data created for that purpose.\n",
    "\n",
    "### Create the data for testing\n",
    "\n",
    "The set of data used in this particular test were created with the MIRI Data Simulator (MIRISim). Referring to the MIRISim link, you can see how to set up and run the simulator to re-create the input files if you wish. The data was run with a scene.ini file that specified what the scene should look like, with coordinates for the stars given in units of arcsecond offsets from the center of the field of view. The scene.ini file as well as the setup files simuation.ini and simulator.ini are needed to run the simulation.\n",
    "\n",
    "Once in the mirisim conda environment, the simulation is run with the command line:\n",
    "> mirisim simulation.ini\n",
    "\n",
    "The simulator created four files, two exposures each at two different dither positions, using the specified filter. Make sure the WCSAXES header keyword in the SCI extension is set to 2 and not 4. If it is set to 4, change it to 2.\n",
    "\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline_ID\"></a>\n",
    "## Run JWST Pipelines\n",
    "\n",
    "The four files were then run individually through the calwebb_detector1 and calwebb_image2 pipelines. When running the calwebb_detector1 pipeline, increase the threshold for a detection in the jump step from 4 sigma to 10 sigma to avoid a current issue where the jump detection step flags a large percentage of pixels as jumps. This can be done on the command line. (commands to be typed start with $)\n",
    "\n",
    "The pipelines can be run on the command line with the following commands or put into a script while using the pipeline conda environment.\n",
    "\n",
    "$ strun calwebb_detector1.cfg filename --steps.jump.rejection_threshold 10.0\n",
    "\n",
    "The output of the calwebb_detector1 pipeline is a set of four *rate.fits files which will then be run through the calwebb_image2 pipeline.\n",
    "\n",
    "$ strun calwebb_image2.cfg filename\n",
    "\n",
    "The output of the calwebb_image2 pipeline was then a set of four *cal.fits files. An association table was created that included these four files as input, and then the files and the association table were run through the calwebb_image3 pipeline. \n",
    "\n",
    "The cal files are stored in artifactory, and this notebook is meant to pull those files for the test of resample. Step through the cells of this notebook to run calwebb_image3 and then check the alignment.\n",
    "\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T17:28:02.104189Z",
     "iopub.status.busy": "2022-09-20T17:28:02.103966Z",
     "iopub.status.idle": "2022-09-20T17:28:02.111903Z",
     "shell.execute_reply": "2022-09-20T17:28:02.111142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TemporaryDirectory '/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/tmp/tmp1yaqjjq4'>\n"
     ]
    }
   ],
   "source": [
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "data_dir = TemporaryDirectory()\n",
    "os.chdir(data_dir.name)\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T17:28:02.114492Z",
     "iopub.status.busy": "2022-09-20T17:28:02.114055Z",
     "iopub.status.idle": "2022-09-20T17:28:02.118810Z",
     "shell.execute_reply": "2022-09-20T17:28:02.118064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRDS cache location: /tmp/crds_cache\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if 'CRDS_CACHE_TYPE' in os.environ:\n",
    "    if os.environ['CRDS_CACHE_TYPE'] == 'local':\n",
    "        os.environ['CRDS_PATH'] = os.path.join(os.environ['HOME'], 'crds', 'cache')\n",
    "    elif os.path.isdir(os.environ['CRDS_CACHE_TYPE']):\n",
    "        os.environ['CRDS_PATH'] = os.environ['CRDS_CACHE_TYPE']\n",
    "print('CRDS cache location: {}'.format(os.environ['CRDS_PATH']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"imports_ID\"></a>\n",
    "# Imports\n",
    "The following packages will need to be imported for the scripts to work.\n",
    "\n",
    "\n",
    "* astropy.io for opening files\n",
    "* astropy.stats for sigma clipping routine\n",
    "* astropy.visualization for image plotting\n",
    "* ci_watson.artifactory_helpers to read in data from artifactory\n",
    "* jwst.datamodels for opening files as a JWST Datamodel\n",
    "* jwst.pipeline to run the pipeline step/module\n",
    "* jwst.associations to create association table\n",
    "* numpy for calculations\n",
    "* matplotlib.pyplot.plt to generate plot\n",
    "* os for path information  \n",
    "* photutils for star finding and aperture photometry\n",
    "* regtest to retrieve data from artifactory needed to run notebook\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T17:28:02.121489Z",
     "iopub.status.busy": "2022-09-20T17:28:02.120866Z",
     "iopub.status.idle": "2022-09-20T17:28:03.763872Z",
     "shell.execute_reply": "2022-09-20T17:28:03.763099Z"
    },
    "nbpresent": {
     "id": "45177853-942e-4949-9e30-f544d70ef5f4"
    }
   },
   "outputs": [],
   "source": [
    "from astropy.io import ascii, fits\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.table import Column\n",
    "from astropy.visualization import SqrtStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from ci_watson.artifactory_helpers import get_bigdata\n",
    "import glob\n",
    "from itertools import product\n",
    "from jwst.datamodels import DrizProductModel, ImageModel\n",
    "from jwst.pipeline import Detector1Pipeline, Image2Pipeline, Image3Pipeline\n",
    "from jwst import associations\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base\n",
    "from jwst.associations import asn_from_list\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from photutils import CircularAperture, DAOStarFinder, CircularAnnulus, aperture_photometry\n",
    "from jwst.regtest.regtestdata import RegtestData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in uncal data from artifactory \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T17:28:03.767855Z",
     "iopub.status.busy": "2022-09-20T17:28:03.767498Z",
     "iopub.status.idle": "2022-09-20T17:28:27.714669Z",
     "shell.execute_reply": "2022-09-20T17:28:27.713559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading input files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Downloads\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading input files\")\n",
    " \n",
    "#This readnoise file is needed for use with simulated data which has higher readnoise than actual data.\n",
    "readnoise = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'jump',                     \n",
    "                     'jump_miri_test', \n",
    "                     'jwst_mirisim_readnoise.fits')\n",
    "\n",
    "filelist = ['starfield_50star4ptdither_seq1_MIRIMAGE_F1130Wexp1.fits', \n",
    "            'starfield_50star4ptdither_seq1_MIRIMAGE_F1130Wexp2.fits',\n",
    "            'starfield_50star4ptdither_seq2_MIRIMAGE_F1130Wexp1.fits',\n",
    "            'starfield_50star4ptdither_seq2_MIRIMAGE_F1130Wexp2.fits',\n",
    "            'starfield_50star4ptdither_seq3_MIRIMAGE_F1130Wexp1.fits',\n",
    "            'starfield_50star4ptdither_seq3_MIRIMAGE_F1130Wexp2.fits',\n",
    "            'starfield_50star4ptdither_seq4_MIRIMAGE_F1130Wexp1.fits',\n",
    "            'starfield_50star4ptdither_seq4_MIRIMAGE_F1130Wexp2.fits']\n",
    "\n",
    "for file in filelist:\n",
    "    input_file = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'outlier_detection',\n",
    "                     'outlier_detection_miri_test',\n",
    "                     file)\n",
    "\n",
    "print(\"Finished Downloads\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Calwebb_detector1 to process files to ramp fit (slope) files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T17:28:27.719070Z",
     "iopub.status.busy": "2022-09-20T17:28:27.718627Z",
     "iopub.status.idle": "2022-09-20T17:28:30.728980Z",
     "shell.execute_reply": "2022-09-20T17:28:30.727519Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,733 - stpipe.Detector1Pipeline - INFO - Detector1Pipeline instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,735 - stpipe.Detector1Pipeline.group_scale - INFO - GroupScaleStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,736 - stpipe.Detector1Pipeline.dq_init - INFO - DQInitStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,737 - stpipe.Detector1Pipeline.saturation - INFO - SaturationStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,738 - stpipe.Detector1Pipeline.ipc - INFO - IPCStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,740 - stpipe.Detector1Pipeline.superbias - INFO - SuperBiasStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,741 - stpipe.Detector1Pipeline.refpix - INFO - RefPixStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,742 - stpipe.Detector1Pipeline.rscd - INFO - RscdStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,744 - stpipe.Detector1Pipeline.firstframe - INFO - FirstFrameStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,745 - stpipe.Detector1Pipeline.lastframe - INFO - LastFrameStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,746 - stpipe.Detector1Pipeline.linearity - INFO - LinearityStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,748 - stpipe.Detector1Pipeline.dark_current - INFO - DarkCurrentStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,749 - stpipe.Detector1Pipeline.reset - INFO - ResetStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,750 - stpipe.Detector1Pipeline.persistence - INFO - PersistenceStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,753 - stpipe.Detector1Pipeline.jump - INFO - JumpStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,754 - stpipe.Detector1Pipeline.ramp_fit - INFO - RampFitStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,755 - stpipe.Detector1Pipeline.gain_scale - INFO - GainScaleStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,874 - stpipe.Detector1Pipeline - INFO - Step Detector1Pipeline running with args ('starfield_50star4ptdither_seq1_MIRIMAGE_F1130Wexp1.fits',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:27,885 - stpipe.Detector1Pipeline - INFO - Step Detector1Pipeline parameters are: {'pre_hooks': [], 'post_hooks': [], 'output_file': '/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/tmp/tmp1yaqjjq4/starfield_50star4ptdither_seq1_MIRIMAGE_F1130Wexp1.fits', 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'save_calibrated_ramp': False, 'steps': {'group_scale': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': ''}, 'dq_init': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': ''}, 'saturation': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'n_pix_grow_sat': 1}, 'ipc': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': ''}, 'superbias': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': ''}, 'refpix': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': True, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'odd_even_columns': True, 'use_side_ref_pixels': True, 'side_smoothing_length': 11, 'side_gain': 1.0, 'odd_even_rows': True}, 'rscd': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'type': 'baseline'}, 'firstframe': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': ''}, 'lastframe': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': ''}, 'linearity': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': ''}, 'dark_current': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'dark_output': None}, 'reset': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': ''}, 'persistence': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'input_trapsfilled': '', 'flag_pers_cutoff': 40.0, 'save_persistence': False, 'save_trapsfilled': True}, 'jump': {'pre_hooks': [], 'post_hooks': [], 'output_file': '/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/tmp/tmp1yaqjjq4/starfield_50star4ptdither_seq1_MIRIMAGE_F1130Wexp1.fits', 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'rejection_threshold': 10.0, 'three_group_rejection_threshold': 6.0, 'four_group_rejection_threshold': 5.0, 'maximum_cores': 'none', 'flag_4_neighbors': True, 'max_jump_to_flag_neighbors': 1000.0, 'min_jump_to_flag_neighbors': 10.0, 'after_jump_flag_dn1': 0.0, 'after_jump_flag_time1': 0.0, 'after_jump_flag_dn2': 0.0, 'after_jump_flag_time2': 0.0}, 'ramp_fit': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'int_name': '', 'save_opt': False, 'opt_name': '', 'suppress_one_group': True, 'maximum_cores': 'none'}, 'gain_scale': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': ''}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  8  images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:29,206 - stpipe.Detector1Pipeline - INFO - Prefetching reference files for dataset: 'starfield_50star4ptdither_seq1_MIRIMAGE_F1130Wexp1.fits' reftypes = ['dark', 'gain', 'ipc', 'linearity', 'mask', 'persat', 'reset', 'rscd', 'saturation', 'superbias', 'trapdensity', 'trappars']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:28:29,277 - CRDS - INFO -  Fetching  /tmp/crds_cache/mappings/jwst/jwst_nirspec_superbias_0051.rmap   26.4 K bytes  (1 / 13 files) (0 / 124.3 K bytes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py\", line 347, in local_bestrefs\n",
      "    return hv_best_references(context, parameters, reftypes)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py\", line 367, in hv_best_references\n",
      "    ctx = get_symbolic_mapping(context_file, cached=True)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py\", line 670, in get_symbolic_mapping\n",
      "    return get_pickled_mapping(   # reviewed\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py\", line 306, in __call__\n",
      "    key, result = self._readonly(*args, **keys)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py\", line 293, in _readonly\n",
      "    return key, self.uncached(*args, **keys)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py\", line 695, in get_pickled_mapping\n",
      "    loaded = rmap.asmapping(mapping, cached=cached, **keys)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/rmap.py\", line 1665, in asmapping\n",
      "    return get_cached_mapping(filename_or_mapping, **keys)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/rmap.py\", line 1592, in get_cached_mapping\n",
      "    return _load_mapping(mapping, **keys)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py\", line 306, in __call__\n",
      "    key, result = self._readonly(*args, **keys)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py\", line 293, in _readonly\n",
      "    return key, self.uncached(*args, **keys)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/rmap.py\", line 1643, in _load_mapping\n",
      "    return cls.from_file(mapping, **keys)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/rmap.py\", line 266, in from_file\n",
      "    text = utils.get_uri_content(filename)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py\", line 737, in get_uri_content\n",
      "    with open(uri, mode) as file:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/crds_cache/mappings/jwst/jwst_0982.pmap'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py\", line 653, in download\n",
      "    return proxy.apply_with_retries(self.download_core, name, localpath)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/proxy.py\", line 50, in apply_with_retries\n",
      "    raise exc2\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/proxy.py\", line 44, in apply_with_retries\n",
      "    return func(*pars, **keys)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py\", line 679, in download_core\n",
      "    self.generator_download(generator, localpath)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py\", line 684, in generator_download\n",
      "    with open(localpath, \"wb+\") as outfile:\n",
      "OSError: [Errno 28] No space left on device: '/tmp/crds_cache/mappings/jwst/jwst_nirspec_superbias_0051.rmap'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py\", line 351, in local_bestrefs\n",
      "    api.dump_mappings(context, ignore_cache=ignore_cache)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py\", line 778, in dump_mappings\n",
      "    return dump_mappings3(*args, **keys)[0]\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py\", line 771, in dump_mappings3\n",
      "    return FileCacher(pipeline_context, ignore_cache, raise_exceptions).get_local_files(mappings)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py\", line 594, in get_local_files\n",
      "    n_bytes = self.download_files(downloads, localpaths)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py\", line 634, in download_files\n",
      "    self.download(name, path)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py\", line 656, in download\n",
      "    raise CrdsDownloadError(\n",
      "crds.core.exceptions.CrdsDownloadError: Error fetching data for 'jwst_nirspec_superbias_0051.rmap' at CRDS server 'https://jwst-crds.stsci.edu' with mode 'http' : [Errno 28] No space left on device: '/tmp/crds_cache/mappings/jwst/jwst_nirspec_superbias_0051.rmap'\n"
     ]
    },
    {
     "ename": "CrdsDownloadError",
     "evalue": "Failed caching mapping files: Error fetching data for 'jwst_nirspec_superbias_0051.rmap' at CRDS server 'https://jwst-crds.stsci.edu' with mode 'http' : [Errno 28] No space left on device: '/tmp/crds_cache/mappings/jwst/jwst_nirspec_superbias_0051.rmap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py:347\u001b[0m, in \u001b[0;36mlocal_bestrefs\u001b[0;34m(parameters, reftypes, context, ignore_cache)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;66;03m# Finally do the best refs computation using pmap methods from local code.\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhv_best_references\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreftypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py:367\u001b[0m, in \u001b[0;36mhv_best_references\u001b[0;34m(context_file, header, include, condition)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m\"\"\"Compute the best references for `header` for the given CRDS\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m`context_file`.   This is a local computation using local rmaps and\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03mCPU resources.   If `include` is None,  return results for all\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03mfilekinds appropriate to `header`,  otherwise return only those\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03mfilekinds listed in `include`.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m ctx \u001b[38;5;241m=\u001b[39m \u001b[43mget_symbolic_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m conditioned \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcondition_header(header) \u001b[38;5;28;01mif\u001b[39;00m condition \u001b[38;5;28;01melse\u001b[39;00m header\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py:670\u001b[0m, in \u001b[0;36mget_symbolic_mapping\u001b[0;34m(mapping, observatory, cached, use_pickles, save_pickles, **keys)\u001b[0m\n\u001b[1;32m    669\u001b[0m abs_mapping \u001b[38;5;241m=\u001b[39m translate_date_based_context(mapping, observatory)\n\u001b[0;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_pickled_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# reviewed\u001b[39;49;00m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mabs_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcached\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pickles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_pickles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_pickles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_pickles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py:306\u001b[0m, in \u001b[0;36mCachedFunction.__call__\u001b[0;34m(self, *args, **keys)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03m\"\"\"Compute or fetch func(*args, **keys).  Add the result to the cache.\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03mreturn func(*args, **keys)\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m key, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readonly\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache[key] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py:293\u001b[0m, in \u001b[0;36mCachedFunction._readonly\u001b[0;34m(self, *args, **keys)\u001b[0m\n\u001b[1;32m    292\u001b[0m log\u001b[38;5;241m.\u001b[39mverbose(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncached call\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muncached\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mrepr\u001b[39m(key), verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m key, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muncached\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py:695\u001b[0m, in \u001b[0;36mget_pickled_mapping\u001b[0;34m(mapping, cached, use_pickles, save_pickles, **keys)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43mrmap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masmapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcached\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loaded\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/rmap.py:1665\u001b[0m, in \u001b[0;36masmapping\u001b[0;34m(filename_or_mapping, cached, **keys)\u001b[0m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cached \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcached\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m-> 1665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_cached_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cached \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreadonly\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/rmap.py:1592\u001b[0m, in \u001b[0;36mget_cached_mapping\u001b[0;34m(mapping, **keys)\u001b[0m\n\u001b[1;32m   1591\u001b[0m keys[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloader\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m get_cached_mapping\n\u001b[0;32m-> 1592\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py:306\u001b[0m, in \u001b[0;36mCachedFunction.__call__\u001b[0;34m(self, *args, **keys)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03m\"\"\"Compute or fetch func(*args, **keys).  Add the result to the cache.\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03mreturn func(*args, **keys)\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m key, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readonly\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache[key] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py:293\u001b[0m, in \u001b[0;36mCachedFunction._readonly\u001b[0;34m(self, *args, **keys)\u001b[0m\n\u001b[1;32m    292\u001b[0m log\u001b[38;5;241m.\u001b[39mverbose(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncached call\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muncached\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mrepr\u001b[39m(key), verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m key, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muncached\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/rmap.py:1643\u001b[0m, in \u001b[0;36m_load_mapping\u001b[0;34m(mapping, **keys)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/rmap.py:266\u001b[0m, in \u001b[0;36mMapping.from_file\u001b[0;34m(cls, basename, *args, **keys)\u001b[0m\n\u001b[1;32m    265\u001b[0m     filename \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mlocate_mapping(basename)\n\u001b[0;32m--> 266\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_uri_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_string(text, basename, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkeys)\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py:737\u001b[0m, in \u001b[0;36mget_uri_content\u001b[0;34m(uri, mode)\u001b[0m\n\u001b[1;32m    736\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (mode\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 737\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/crds_cache/mappings/jwst/jwst_0982.pmap'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py:653\u001b[0m, in \u001b[0;36mFileCacher.download\u001b[0;34m(self, name, localpath)\u001b[0m\n\u001b[1;32m    652\u001b[0m     utils\u001b[38;5;241m.\u001b[39mensure_dir_exists(localpath)\n\u001b[0;32m--> 653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mproxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_retries\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_core\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocalpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/proxy.py:50\u001b[0m, in \u001b[0;36mapply_with_retries\u001b[0;34m(func, *pars, **keys)\u001b[0m\n\u001b[1;32m     49\u001b[0m         exc2 \u001b[38;5;241m=\u001b[39m exc\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc2\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/proxy.py:44\u001b[0m, in \u001b[0;36mapply_with_retries\u001b[0;34m(func, *pars, **keys)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py:679\u001b[0m, in \u001b[0;36mFileCacher.download_core\u001b[0;34m(self, name, localpath)\u001b[0m\n\u001b[1;32m    678\u001b[0m     generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_data_http(name)\n\u001b[0;32m--> 679\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocalpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_file(name, localpath)\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py:684\u001b[0m, in \u001b[0;36mFileCacher.generator_download\u001b[0;34m(self, generator, localpath)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;124;03m\"\"\"Read all bytes from `generator` until file is downloaded to `localpath.`\"\"\"\u001b[39;00m\n\u001b[0;32m--> 684\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlocalpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m outfile:\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m generator:\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device: '/tmp/crds_cache/mappings/jwst/jwst_nirspec_superbias_0051.rmap'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mCrdsDownloadError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py:351\u001b[0m, in \u001b[0;36mlocal_bestrefs\u001b[0;34m(parameters, reftypes, context, ignore_cache)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 351\u001b[0m     \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump_mappings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CrdsError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py:778\u001b[0m, in \u001b[0;36mdump_mappings\u001b[0;34m(*args, **keys)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;124;03m\"\"\"See dump_mappings3.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \n\u001b[1;32m    776\u001b[0m \u001b[38;5;124;03mReturns { mapping_basename :   mapping_local_filepath ... }\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdump_mappings3\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py:771\u001b[0m, in \u001b[0;36mdump_mappings3\u001b[0;34m(pipeline_context, ignore_cache, mappings, raise_exceptions)\u001b[0m\n\u001b[1;32m    770\u001b[0m mappings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(mappings))))\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFileCacher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_local_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmappings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py:594\u001b[0m, in \u001b[0;36mFileCacher.get_local_files\u001b[0;34m(self, names)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m downloads:\n\u001b[0;32m--> 594\u001b[0m     n_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownloads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocalpaths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py:634\u001b[0m, in \u001b[0;36mFileCacher.download_files\u001b[0;34m(self, downloads, localpaths)\u001b[0m\n\u001b[1;32m    633\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(file_progress(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, path, \u001b[38;5;28mbytes\u001b[39m, bytes_so_far, total_bytes, nth_file, total_files))\n\u001b[0;32m--> 634\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m bytes_so_far \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(path)\u001b[38;5;241m.\u001b[39mst_size\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py:656\u001b[0m, in \u001b[0;36mFileCacher.download\u001b[0;34m(self, name, localpath)\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_file(localpath)\n\u001b[0;32m--> 656\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CrdsDownloadError(\n\u001b[1;32m    657\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError fetching data for\u001b[39m\u001b[38;5;124m\"\u001b[39m, srepr(name),\n\u001b[1;32m    658\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mat CRDS server\u001b[39m\u001b[38;5;124m\"\u001b[39m, srepr(get_crds_server()),\n\u001b[1;32m    659\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith mode\u001b[39m\u001b[38;5;124m\"\u001b[39m, srepr(config\u001b[38;5;241m.\u001b[39mget_download_mode()),\n\u001b[1;32m    660\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(exc)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:  \u001b[38;5;66;03m#  mainly for control-c,  catch it and throw it.\u001b[39;00m\n",
      "\u001b[0;31mCrdsDownloadError\u001b[0m: Error fetching data for 'jwst_nirspec_superbias_0051.rmap' at CRDS server 'https://jwst-crds.stsci.edu' with mode 'http' : [Errno 28] No space left on device: '/tmp/crds_cache/mappings/jwst/jwst_nirspec_superbias_0051.rmap'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mCrdsDownloadError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m pipe1\u001b[38;5;241m.\u001b[39moutput_file \u001b[38;5;241m=\u001b[39m outname\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.fits\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Run pipeline on each file\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m rampfile \u001b[38;5;241m=\u001b[39m \u001b[43mpipe1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m slopelist\u001b[38;5;241m.\u001b[39mappend(rampfile)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Close the input files\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#file.close()\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/stpipe/step.py:481\u001b[0m, in \u001b[0;36mStep.run\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefetch_references:\n\u001b[0;32m--> 481\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m         step_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/stpipe/step.py:598\u001b[0m, in \u001b[0;36mStep.prefetch\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;66;03m# prefetch truly occurs at the Pipeline (or subclass) level.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_file_types) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip:\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_precache_references\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/stpipe/pipeline.py:313\u001b[0m, in \u001b[0;36mPipeline._precache_references\u001b[0;34m(self, input_file)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen_model(input_file, asn_n_members\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    312\u001b[0m                         asn_exptypes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscience\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mas\u001b[39;00m model:\n\u001b[0;32m--> 313\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_precache_references_opened\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mIOError\u001b[39;00m):\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirst argument \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m does not appear to be a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(input_file))\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/stpipe/pipeline.py:336\u001b[0m, in \u001b[0;36mPipeline._precache_references_opened\u001b[0;34m(self, model_or_container)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_precache_references_opened(contained_model)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;66;03m# precache a single model object\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_precache_references_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_or_container\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/stpipe/pipeline.py:360\u001b[0m, in \u001b[0;36mPipeline._precache_references_impl\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    356\u001b[0m fetch_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_file_types) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(ovr_refs\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrefetching reference files for dataset: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mrepr\u001b[39m(model\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mfilename) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    359\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m reftypes = \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mrepr\u001b[39m(fetch_types))\n\u001b[0;32m--> 360\u001b[0m crds_refs \u001b[38;5;241m=\u001b[39m \u001b[43mcrds_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_multiple_reference_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_crds_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrds_observatory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m ref_path_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(crds_refs\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(ovr_refs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (reftype, refpath) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(ref_path_map\u001b[38;5;241m.\u001b[39mitems()):\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/stpipe/crds_client.py:55\u001b[0m, in \u001b[0;36mget_multiple_reference_paths\u001b[0;34m(parameters, reference_file_types, observatory)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst argument must be a dict of parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m log\u001b[38;5;241m.\u001b[39mset_log_time(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 55\u001b[0m refpaths \u001b[38;5;241m=\u001b[39m \u001b[43m_get_refpaths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreference_file_types\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservatory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m refpaths\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/stpipe/crds_client.py:68\u001b[0m, in \u001b[0;36m_get_refpaths\u001b[0;34m(data_dict, reference_file_types, observatory)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m crds_cache_locking\u001b[38;5;241m.\u001b[39mget_cache_lock():\n\u001b[0;32m---> 68\u001b[0m     bestrefs \u001b[38;5;241m=\u001b[39m \u001b[43mcrds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetreferences\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreftypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference_file_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservatory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobservatory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m refpaths \u001b[38;5;241m=\u001b[39m {filetype: filepath \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m filepath\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m (filetype, filepath) \u001b[38;5;129;01min\u001b[39;00m bestrefs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m refpaths\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py:122\u001b[0m, in \u001b[0;36mgetreferences\u001b[0;34m(parameters, reftypes, context, ignore_cache, observatory, fast)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetreferences\u001b[39m(parameters, reftypes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ignore_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     82\u001b[0m                   observatory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjwst\u001b[39m\u001b[38;5;124m\"\u001b[39m, fast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    This is the top-level get reference call for all of CRDS.  Based on\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    `parameters`, getreferences() will download/cache the corresponding best\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m      cached reference file.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     final_context, bestrefs \u001b[38;5;241m=\u001b[39m \u001b[43m_initial_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgetreferences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreftypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservatory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfast\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# Attempt to cache the recommended references,  which unlike dump_mappings\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# should work without network access if files are already cached.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     best_refs_paths \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mcache_references(\n\u001b[1;32m    128\u001b[0m         final_context, bestrefs, ignore_cache\u001b[38;5;241m=\u001b[39mignore_cache)\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py:209\u001b[0m, in \u001b[0;36m_initial_recommendations\u001b[0;34m(name, parameters, reftypes, context, ignore_cache, observatory, fast)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    208\u001b[0m     log\u001b[38;5;241m.\u001b[39mverbose(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing best references locally.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 209\u001b[0m     bestrefs \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_bestrefs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreftypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreftypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m     log\u001b[38;5;241m.\u001b[39mverbose(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing best references remotely.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py:354\u001b[0m, in \u001b[0;36mlocal_bestrefs\u001b[0;34m(parameters, reftypes, context, ignore_cache)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CrdsError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    353\u001b[0m     traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CrdsDownloadError(\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed caching mapping files:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(exc)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hv_best_references(context, parameters, reftypes)\n",
      "\u001b[0;31mCrdsDownloadError\u001b[0m: Failed caching mapping files: Error fetching data for 'jwst_nirspec_superbias_0051.rmap' at CRDS server 'https://jwst-crds.stsci.edu' with mode 'http' : [Errno 28] No space left on device: '/tmp/crds_cache/mappings/jwst/jwst_nirspec_superbias_0051.rmap'"
     ]
    }
   ],
   "source": [
    "# Run the calwebb_detector1 pipeline\n",
    "\n",
    "# set up pipeline parameters \n",
    "rej_thresh=10.0  # rejection threshold for jump step\n",
    "\n",
    "print('There are ', len(filelist), ' images.')\n",
    "    \n",
    "slopelist = []    \n",
    "    \n",
    "# loop over list of files\n",
    "for file in filelist:\n",
    "    \n",
    "    # set up pipeline parameters for input\n",
    "    pipe1 = Detector1Pipeline()\n",
    "    pipe1.jump.rejection_threshold = rej_thresh\n",
    "    pipe1.jump.override_readnoise = readnoise\n",
    "    pipe1.ramp_fit.override_readnoise = readnoise\n",
    "    pipe1.refpix.skip = True  # needs update to simulator for this to work properly with simulated data\n",
    "       \n",
    "    # set up output file name\n",
    "    base, remainder = file.split('.')\n",
    "    outname = base\n",
    "        \n",
    "    pipe1.jump.output_file = outname+'.fits'    \n",
    "    #pipe1.ramp_fit.output_file = outname+'.fits'\n",
    "    pipe1.output_file = outname+'.fits'\n",
    "\n",
    "    # Run pipeline on each file\n",
    "    rampfile = pipe1.run(file)\n",
    "    slopelist.append(rampfile)\n",
    "    \n",
    "    # Close the input files\n",
    "    #file.close()\n",
    "\n",
    "print('Detector 1 steps completed on all files.')\n",
    "print(slopelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Calwebb_image2 on files output from detector1 to create calibrated individual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Calwebb_image2 on output files from detector1\n",
    "    \n",
    "print('There are ', len(slopelist), ' images.')\n",
    "    \n",
    "callist = []\n",
    "\n",
    "# cycle through files\n",
    "for rampfile in slopelist:\n",
    "    \n",
    "    # create an object for the pipeline    \n",
    "    pipe2 = Image2Pipeline()\n",
    "\n",
    "    filename = rampfile.meta.filename\n",
    "    # Set pipeline parameters\n",
    "\n",
    "    pipe2.save_results = True\n",
    "    pipe2.output_file = filename +'_cal.fits'\n",
    "    pipe2.resample.save_results = True\n",
    "    pipe2.suffix = None\n",
    "\n",
    "    calfile = pipe2.run(rampfile)\n",
    "\n",
    "    callist.append(calfile)\n",
    "\n",
    "print(callist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an association table for the cal files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use asn_from_list to create association table\n",
    "\n",
    "calfiles = glob.glob('starfield*_cal.fits')\n",
    "asn = asn_from_list.asn_from_list(calfiles, rule=DMS_Level3_Base, product_name='starfield_50star4ptdither_combined.fits')\n",
    "\n",
    "# use this if you need to add non'science' exposure types\n",
    "#asn['products'][0]['members'][1]['exptype'] = 'background'\n",
    "#asn['products'][0]['members'][2]['exptype'] = 'sourcecat'\n",
    "\n",
    "# dump association table to a .json file for use in image3\n",
    "with open('starfield_50star4ptdither_asnfile.json', 'w') as fp:\n",
    "    fp.write(asn.dump()[1])\n",
    "\n",
    "print(asn)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"runpipeline_ID\"></a>\n",
    "# Use an association table for your cal files and run them through calwebb_image3\n",
    "\n",
    "Use the association table to process the .cal files that were output from calwebb_image2. That will be the input for calwebb_image3 that uses the resample step to combine each of the individual images.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use regtest infrastructure to access all input files associated with the association file\n",
    "\n",
    "#rtdata = RegtestData(inputs_root=\"jwst_validation_notebooks\", env=\"validation_data\")\n",
    "#rtdata.get_asn(\"resample/resample_miri_test/starfield_50star4ptdither_771_asnfile.json\")\n",
    "#rtdata.input #this should be the list of files associated with the asn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Calwebb_image3 on the association table\n",
    "    \n",
    "# set any specific parameters\n",
    "# tweakreg parameters to allow data to run\n",
    "fwhm = 3.318 #3.27  # Gaussian kernel FWHM of objects expected, default=2.5\n",
    "minobj = 5  # minimum number of objects needed to match positions for a good fit, default=15\n",
    "snr = 50 # signal to noise threshold, default=5\n",
    "sigma = 3 # clipping limit, in sigma units, used when performing fit, default=3\n",
    "fit_geom ='shift' # ftype of affine transformation to be considered when fitting catalogs, default='general'\n",
    "use2dhist = False  # boolean indicating whether to use 2D histogram to find initial offset, default=True\n",
    "   \n",
    "pipe3=Image3Pipeline()    \n",
    "pipe3.tweakreg.kernel_fwhm = fwhm\n",
    "pipe3.tweakreg.snr_threshold = snr\n",
    "pipe3.tweakreg.minobj = minobj\n",
    "pipe3.tweakreg.sigma = sigma\n",
    "pipe3.tweakreg.fitgeometry = fit_geom\n",
    "pipe3.tweakreg.use2dhist = use2dhist\n",
    "#pipe3.tweakreg.skip = True        # test to see if this affects the final output\n",
    "pipe3.source_catalog.save_results = True\n",
    "pipe3.save_results = True\n",
    "\n",
    "# run Image3\n",
    "\n",
    "#im = pipe3.run(rtdata.input)\n",
    "image = pipe3.run('starfield_50star4ptdither_asnfile.json')\n",
    "print('Image 3 pipeline finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"runscript_ID\"></a>\n",
    "# Find stars in image and determine their coordinates\n",
    "\n",
    "The output of the pipeline command in the previous step (given our association table) is an i2d.fits file. This file is in the format of a JWST Data model type of DrizProductModel and should be opened as such. It is this file that we will use for source finding and to determine whether the stars are found in the expected locations. The i2d file and the associated text file containing the input coordinates of the stars can be found in artifactory.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in combined i2d data file and list of coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the combined data file and list of coordinates\n",
    "\n",
    "im = ImageModel('starfield_50star4ptdither_combined_i2d.fits')\n",
    "pixarea = im.meta.photometry.pixelarea_steradians\n",
    "print('Pixel area in steradians', pixarea)\n",
    "\n",
    "coords = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'resample',\n",
    "                     'resample_miri_test', \n",
    "                     'radec_4ptdith_50star_mosaic_coords.txt')\n",
    "\n",
    "# read in text file with RA and Dec input coordinates\n",
    "RA_in, Dec_in = np.loadtxt( coords, dtype=str, unpack=True)\n",
    "\n",
    "# put RA and Dec into floats\n",
    "RA_sim = RA_in.astype(float)\n",
    "Dec_sim = Dec_in.astype(float)\n",
    "\n",
    "\n",
    "# pull out data portion of input file\n",
    "data = im.data\n",
    "\n",
    "# print stats on input image\n",
    "mean, median, std = sigma_clipped_stats(data, sigma=200.0, maxiters=5)  # default sigma=3\n",
    "print('Image mean, median and std',mean, median, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run DAOStar finder to find sources in the image and examine the image and positions marked. \n",
    "The block of code below will find the sources in the image, create apertures for each source found, and output the table of x, y coordinates along with the peak pixel value. It will also show a scaled version of the image and mark in blue the positions of sources found.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DAOStarFinder to find sources in image\n",
    "\n",
    "ap_radius = 5.  # radius for aperture for centroiding and photometry\n",
    "\n",
    "daofind = DAOStarFinder(fwhm=3.0, threshold=10.*std)    # default threshold=5*std, fwhm=3\n",
    "sources = daofind(data)    \n",
    "\n",
    "sources.pprint_all()\n",
    "#print(sources['xcentroid','ycentroid','peak'])   \n",
    "\n",
    "# Create apertures for x,y positions\n",
    "positions = tuple(zip(sources['xcentroid'], sources['ycentroid']))\n",
    "#print(positions)\n",
    "\n",
    "#positions = (sources['xcentroid'], sources['ycentroid'])\n",
    "apertures = CircularAperture(positions, r=ap_radius)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark sources on image frame to see if the correct sources were found\n",
    "norm = ImageNormalize(stretch=SqrtStretch())\n",
    "# keep image stretch in mind for plotting. sky subtracted range ~ (-15, 10), single sample ~ (0, 20)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(data, cmap='Greys', origin='lower', vmin=8,vmax=15)#, norm=norm)\n",
    "apertures.plot(color='red', lw=2.5) #, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run photometry on apertures (with a specified annulus for background subtraction)\n",
    "\n",
    "Set a specified annulus (inner and outer radii for the annulus).\n",
    "\n",
    "Run photometry on aperture and annuli.\n",
    "\n",
    "Subtract background values in annulus from aperture photometry.\n",
    "\n",
    "Output should be a table of photometry values printed to the screen (full table has columns id, xcenter, ycenter, aperture_sum and the added columns annulus_median, aperture_bkg and aperture_sum_bkgsub). You can choose which columns you wish to see printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set values for inner and outer annuli to collect background counts\n",
    "\n",
    "inner_annulus = 10.\n",
    "outer_annulus = 15.\n",
    "\n",
    "# set up annulus for background\n",
    "background_aper = CircularAnnulus(positions, r_in=inner_annulus, r_out=outer_annulus)\n",
    "\n",
    "# perform photometry on apertures for targets and background annuli\n",
    "phot_table = aperture_photometry(im.data, apertures)\n",
    "\n",
    "# perform background subtraction with outlier rejection\n",
    "bkg_median = []\n",
    "bkg_mask = background_aper.to_mask(method='center')\n",
    "bmask = bkg_mask[0]\n",
    "for mask in bkg_mask:\n",
    "    aper_data = bmask.multiply(data)\n",
    "    aper_data = aper_data[mask.data > 0]\n",
    "    \n",
    "    # perform sigma-clipped median\n",
    "    _, median_sigclip, _ = sigma_clipped_stats(aper_data)\n",
    "    bkg_median.append(median_sigclip)\n",
    "bkg_median = np.array(bkg_median)\n",
    "\n",
    "\n",
    "# do calculations on background regions found in annuli\n",
    "# Get average background per pixel\n",
    "phot_table['annulus_median'] = bkg_median\n",
    "# Get total background in the science aperture (per pixel * area in aperture)\n",
    "phot_table['aperture_bkg'] = bkg_median * apertures.area\n",
    "# subtract background in aperture from flux in aperture\n",
    "phot_table['aperture_sum_bkgsub'] = phot_table['aperture_sum'] - phot_table['aperture_bkg']\n",
    "\n",
    "# put aperture sum in pixel scale\n",
    "phot_table['scaled_ap_sum_bkgsub'] = phot_table['aperture_sum_bkgsub'] * pixarea\n",
    "\n",
    "#print(phot_table['aperture_sum','annulus_median','aperture_bkg','aperture_sum_bkgsub','scaled_ap_sum_bkgsub'])\n",
    "\n",
    "phot_table_sub = phot_table['aperture_sum','annulus_median','aperture_bkg','aperture_sum_bkgsub','scaled_ap_sum_bkgsub']\n",
    "phot_table_sub.pprint_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put x, y coordinates into RA and Dec using the wcs information from the files.\n",
    "The output of the next block of code should be a table showing the x and y centroid positions as well as the associated RA and Dec values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using wcs info from images, put coordinates into RA, Dec\n",
    "ra, dec = im.meta.wcs(sources['xcentroid'], sources['ycentroid'])\n",
    "\n",
    "# add RA, Dec to sources table\n",
    "\n",
    "ra_col = Column(name='RA', data=ra)\n",
    "dec_col = Column(name='Dec', data=dec)\n",
    "sources.add_column(ra_col)\n",
    "sources.add_column(dec_col)\n",
    "\n",
    "# print RA, Dec for each x, y position found\n",
    "#print(sources['xcentroid', 'ycentroid', 'RA', 'Dec'])  \n",
    "\n",
    "sources_sub = sources['xcentroid', 'ycentroid', 'RA', 'Dec']\n",
    "sources_sub.pprint_all()\n",
    "\n",
    "# add option to print out list of sources with flux values\n",
    "outtable = 'sourcelist_phot_rate.txt'\n",
    "sources.add_column(phot_table['aperture_sum'])\n",
    "sources.add_column(phot_table['aperture_sum_bkgsub'])\n",
    "sources.add_column(phot_table['scaled_ap_sum_bkgsub'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the RA and Dec positions used to create the simulated data to the values found in the output image.\n",
    "Difference each set of RA and Dec coordinates in both the input list and the found coordinates, taking into account any angles close to 360/0 degrees. If the difference for both the RA and Dec are below a set tolerance, then the positions match. Take the matched positions and convert the differences from degrees to milli arcseconds, and output the RA and Dec positions as well as the differences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare input RA, Dec to found RA, Dec\n",
    "print('       RA found       Dec found    RA_Diff (mas)  Dec_diff (mas)  Bkg sub flux  pass/fail')\n",
    "\n",
    "deltara = []\n",
    "deltadec = []\n",
    "\n",
    "for i in np.arange(0,len(RA_sim)):\n",
    "    for j in np.arange(0,len(ra)):\n",
    "        ra_diff = 180 - abs(abs(RA_sim[i] - ra[j])-180)\n",
    "        dec_diff = 180 - abs(abs(Dec_sim[i] - dec[j])-180)\n",
    "\n",
    "        if ra_diff < 1e-5 and dec_diff < 1e-5:\n",
    "            # put differences in milliarcseconds\n",
    "            ra_diff = ra_diff * 3600000\n",
    "            dec_diff = dec_diff * 3600000\n",
    "            deltara.append(ra_diff)\n",
    "            deltadec.append(dec_diff)\n",
    "\n",
    "            if ra_diff < 30 and dec_diff < 30: \n",
    "                test = 'pass' \n",
    "            else: \n",
    "                test = 'fail'\n",
    "            print('{:15.6f} {:15.6f} {:15.6f} {:15.6f} {:15.5e} {}'.format(ra[j], dec[j], ra_diff, dec_diff, \n",
    "                                                                        phot_table['scaled_ap_sum_bkgsub'][j], test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ra and dec differences\n",
    "plt.title ('Differences in RA and Dec in millarcseconds')\n",
    "plt.ylabel('Delta RA')\n",
    "plt.xlabel('Delta Dec')\n",
    "plt.scatter(deltadec,deltara)\n",
    "plt.show()\n",
    "\n",
    "# Plot should show no differences greater than 30 milliarcseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"residual_ID\"></a>\n",
    "## Compare output RA and Dec to expected values\n",
    "\n",
    "The output RA and Dec coordinates should match the input RA and Dec coordinates to within 1/10 of a PSF FWHM (~0.03 arcsec for F770W).\n",
    "\n",
    "Output RA_Diff and Dec_diff above should be on order of 30 or fewer milliarcseconds.\n",
    "\n",
    "Check to see if your surface brightness is roughly what you expected based on the input data.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check flux values against spatial coordinates\n",
    "\n",
    "Another test that can be done is to plot the flux values against x and y values to check for any systmatic patterns. Previous testing has shown a spatial dependence of the flux with y values, such that there is a rise in surface brightness in the middle, and a drop at the image edges. A quick plot can show whether this problem is fixed or not. Prior to the resample step, there is no pattern, after the step, a pattern is clear. Just do this as a last check. If the scatter is not random, there may be a problem that needs to be checked. (Of course, this only works if you give an equivalent if not equal input count level to each input star.) If there is not an obvious rise in the middle (around y centroid pos of 550-600), then this test passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Flux (MJy) vs. y position on detector')\n",
    "\n",
    "plt.ylim(1.05e-08,1.12e-08)\n",
    "plt.xlabel('y centroid position')\n",
    "plt.ylabel('Surface brightness')\n",
    "plt.plot(sources['ycentroid'], phot_table['scaled_ap_sum_bkgsub'], marker='o',linestyle='') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Flux (MJy) vs. x position on detector')\n",
    "\n",
    "plt.ylim(1.05e-08,1.12e-08)\n",
    "plt.xlabel('x centroid position')\n",
    "plt.ylabel('Surface brightness')\n",
    "plt.plot(sources['xcentroid'], phot_table['scaled_ap_sum_bkgsub'], marker='o',linestyle='') #ylim=(30000,40000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat prior tests with different scaling factor\n",
    "Check previous tests with different scaling factor to see if the RA/Dec values still line up and the photometry gives consistent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all *.cal files and create a new association table.\n",
    "callist = glob.glob('starfield*cal.fits')\n",
    "\n",
    "# use asn_from_list to create association table\n",
    "asn = asn_from_list.asn_from_list(callist, rule=DMS_Level3_Base, product_name='starfield_50star4ptdither_scaled_combined.fits')\n",
    "\n",
    "# use this if you need to add non'science' exposure types\n",
    "#asn['products'][0]['members'][1]['exptype'] = 'background'\n",
    "#asn['products'][0]['members'][2]['exptype'] = 'sourcecat'\n",
    "\n",
    "# dump association table to a .json file for use in image3\n",
    "with open('starfield_50star4ptdither_scaled_asnfile.json', 'w') as fp:\n",
    "    fp.write(asn.dump()[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Calwebb_image3 on the association table\n",
    "    \n",
    "# set any specific parameters\n",
    "# tweakreg parameters to allow data to run\n",
    "fwhm = 5.0  # Gaussian kernel FWHM of objects expected, default=2.5\n",
    "minobj = 5  # minimum number of objects needed to match positions for a good fit, default=15\n",
    "snr = 50 # signal to noise threshold, default=5\n",
    "sigma = 3 # clipping limit, in sigma units, used when performing fit, default=3\n",
    "fit_geom = 'shift' # ftype of affine transformation to be considered when fitting catalogs, default='general'\n",
    "use2dhist = False  # boolean indicating whether to use 2D histogram to find initial offset, default=True\n",
    "\n",
    "ratio = 0.5 # Ratio of input to output pixel scale. A value of 0.5 means the output image would have 4 pixels \n",
    "            # sampling each input pixel.\n",
    "    \n",
    "pipe3=Image3Pipeline()    \n",
    "pipe3.tweakreg.kernel_fwhm = fwhm\n",
    "pipe3.tweakreg.snr_threshold = snr\n",
    "pipe3.tweakreg.minobj = minobj\n",
    "pipe3.tweakreg.sigma = sigma\n",
    "pipe3.tweakreg.fitgeometry = fit_geom\n",
    "#pipe3.tweakreg.skip = True\n",
    "pipe3.tweakreg.use2dhist = use2dhist\n",
    "pipe3.resample.pixel_scale_ratio = ratio\n",
    "pipe3.source_catalog.save_results = True\n",
    "pipe3.save_results = True\n",
    "\n",
    "# run Image3\n",
    "\n",
    "image = pipe3.run('starfield_50star4ptdither_scaled_asnfile.json')\n",
    "print('Image 3 pipeline finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the combined data file and list of coordinates\n",
    "\n",
    "im2 = ImageModel('starfield_50star4ptdither_scaled_combined_i2d.fits')\n",
    "#get pixel scale\n",
    "pixarea2 = im2.meta.photometry.pixelarea_steradians\n",
    "print('Pixel area in steradians', pixarea2)\n",
    "print('Ratio of pixel area scales: original/new scale', pixarea / pixarea2)\n",
    "\n",
    "# read in text file with RA and Dec input coordinates\n",
    "RA_in, Dec_in = np.loadtxt( coords, dtype=str, unpack=True)\n",
    "\n",
    "# put RA and Dec into floats\n",
    "RA_sim = RA_in.astype(float)\n",
    "Dec_sim = Dec_in.astype(float)\n",
    "\n",
    "\n",
    "# pull out data portion of input file\n",
    "data2 = im2.data\n",
    "\n",
    "# print stats on input image\n",
    "mean, median, std = sigma_clipped_stats(data2, sigma=200.0, maxiters=5)  # default sigma=3\n",
    "print('Image mean, median and std',mean, median, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DAOStarFinder to find sources in image\n",
    "pixel_ratio = math.sqrt(pixarea / pixarea2) # ratio of pixel area scales in single dimension (sqrt of area)\n",
    "\n",
    "ap_radius2 = ap_radius * pixel_ratio  # radius for aperture for centroiding and photometry\n",
    "print('New aperture radius', ap_radius2)\n",
    "\n",
    "daofind = DAOStarFinder(fwhm=3.0*pixel_ratio, threshold=10.*std)    # default threshold=5*std, fwhm=3\n",
    "sources2 = daofind(data2)    \n",
    "#print(sources2['xcentroid','ycentroid','peak'])   \n",
    "sources2.pprint_all()\n",
    "\n",
    "# Create apertures for x,y positions\n",
    "positions2 = tuple(zip(sources2['xcentroid'], sources2['ycentroid']))\n",
    "#print(positions)\n",
    "\n",
    "#positions = (sources['xcentroid'], sources['ycentroid'])\n",
    "apertures2 = CircularAperture(positions2, r=ap_radius2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark sources on image frame to see if the correct sources were found\n",
    "norm = ImageNormalize(stretch=SqrtStretch())\n",
    "# keep image stretch in mind for plotting. sky subtracted range ~ (-15, 10), single sample ~ (0, 20)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(data2, cmap='Greys', origin='lower', vmin=8,vmax=15)#, norm=norm)\n",
    "apertures2.plot(color='red', lw=2.5) #, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set values for inner and outer annuli to collect background counts\n",
    "\n",
    "inner_annulus2 = inner_annulus * pixel_ratio\n",
    "outer_annulus2 = outer_annulus * pixel_ratio\n",
    "\n",
    "# set up annulus for background\n",
    "background_aper2 = CircularAnnulus(positions2, r_in=inner_annulus2, r_out=outer_annulus2)\n",
    "\n",
    "# perform photometry on apertures for targets and background annuli\n",
    "phot_table2 = aperture_photometry(im2.data, apertures2)\n",
    "\n",
    "# perform background subtraction with outlier rejection\n",
    "bkg_median = []\n",
    "bkg_mask2 = background_aper2.to_mask(method='center')\n",
    "bmask2 = bkg_mask2[0]\n",
    "for mask in bkg_mask2:\n",
    "    aper_data = bmask2.multiply(data2)\n",
    "    aper_data = aper_data[mask.data > 0]\n",
    "    \n",
    "    # perform sigma-clipped median\n",
    "    _, median_sigclip, _ = sigma_clipped_stats(aper_data)\n",
    "    bkg_median.append(median_sigclip)\n",
    "bkg_median = np.array(bkg_median)\n",
    "\n",
    "\n",
    "# do calculations on background regions found in annuli\n",
    "# Get average background per pixel\n",
    "phot_table2['annulus_median'] = bkg_median\n",
    "# Get total background in the science aperture (per pixel * area in aperture)\n",
    "phot_table2['aperture_bkg'] = bkg_median * apertures2.area\n",
    "# subtract background in aperture from flux in aperture\n",
    "phot_table2['aperture_sum_bkgsub'] = phot_table2['aperture_sum'] - phot_table2['aperture_bkg']\n",
    "# put aperture sum in pixel scale\n",
    "phot_table2['scaled_ap_sum_bkgsub'] = phot_table2['aperture_sum_bkgsub'] * pixarea2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phot_table2_sub = phot_table2['aperture_sum','annulus_median','aperture_bkg','aperture_sum_bkgsub','scaled_ap_sum_bkgsub']\n",
    "phot_table2_sub.pprint_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using wcs info from images, put coordinates into RA, Dec\n",
    "ra2, dec2 = im2.meta.wcs(sources2['xcentroid'], sources2['ycentroid'])\n",
    "\n",
    "# add RA, Dec to sources table\n",
    "\n",
    "ra_col = Column(name='RA', data=ra2)\n",
    "dec_col = Column(name='Dec', data=dec2)\n",
    "sources2.add_column(ra_col)\n",
    "sources2.add_column(dec_col)\n",
    "\n",
    "# print RA, Dec for each x, y position found\n",
    "#print(sources2['xcentroid', 'ycentroid', 'RA', 'Dec']) \n",
    "sources2_sub = sources2['xcentroid', 'ycentroid', 'RA', 'Dec']\n",
    "sources2_sub.pprint_all()\n",
    "\n",
    "# add option to print out list of sources with flux values\n",
    "outtable = 'sourcelist_phot_rate.txt'\n",
    "sources2.add_column(phot_table2['aperture_sum'])\n",
    "sources2.add_column(phot_table2['aperture_sum_bkgsub'])\n",
    "sources2.add_column(phot_table2['scaled_ap_sum_bkgsub'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare input RA, Dec to found RA, Dec\n",
    "print('       RA found       Dec found    RA_Diff (mas)  Dec_diff (mas)  Bkg sub flux  pass/fail')\n",
    "\n",
    "deltara2 = []\n",
    "deltadec2 = []\n",
    "\n",
    "for i in np.arange(0,len(RA_sim)):\n",
    "    for j in np.arange(0,len(ra2)):\n",
    "        ra_diff = 180 - abs(abs(RA_sim[i] - ra2[j])-180)\n",
    "        dec_diff = 180 - abs(abs(Dec_sim[i] - dec2[j])-180)\n",
    "\n",
    "        if ra_diff < 1e-5 and dec_diff < 1e-5:\n",
    "            # put differences in milliarcseconds\n",
    "            ra_diff = ra_diff * 3600000\n",
    "            dec_diff = dec_diff * 3600000\n",
    "            deltara2.append(ra_diff)\n",
    "            deltadec2.append(dec_diff)\n",
    "            if ra_diff < 30 and dec_diff < 30: \n",
    "                test = 'pass' \n",
    "            else: \n",
    "                test = 'fail'\n",
    "            print('{:15.6f} {:15.6f} {:15.6f} {:15.6f} {:15.6e} {}'.format(ra2[j], dec2[j], ra_diff, dec_diff, \n",
    "                                                                        phot_table2['scaled_ap_sum_bkgsub'][j], test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ra and dec differences\n",
    "plt.title ('Differences in RA and Dec in millarcseconds')\n",
    "plt.ylabel('Delta RA')\n",
    "plt.xlabel('Delta Dec')\n",
    "plt.scatter(deltadec2,deltara2)\n",
    "plt.show()\n",
    "\n",
    "# Plot should show no differences greater than 30 milliarcseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare photometry between the original and scaled images\n",
    "plt.title('Flux (MJy) vs. y position on detector')\n",
    "#plt.ylim(33500,39000) # help weed out sources that were erroneously 'hits' (bad pixels, cosmic rays, etc)\n",
    "plt.ylim(1.05e-08,1.12e-08)\n",
    "plt.xlabel('y centroid position')\n",
    "plt.ylabel('Surface brightness')\n",
    "plt.plot(sources['ycentroid'], phot_table['scaled_ap_sum_bkgsub'], marker='o',linestyle='') \n",
    "plt.plot(sources2['ycentroid']/2, phot_table2['scaled_ap_sum_bkgsub'], marker='+',linestyle='') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare photometry between the original and scaled images\n",
    "plt.title('Flux (MJy) vs. x position on detector')\n",
    "#plt.ylim(33500,39000) # help weed out sources that were erroneously 'hits' (bad pixels, cosmic rays, etc)\n",
    "plt.ylim(1.05e-08,1.12e-08)\n",
    "plt.xlabel('x centroid position')\n",
    "plt.ylabel('Surface brightness')\n",
    "plt.plot(sources['xcentroid'], phot_table['scaled_ap_sum_bkgsub'], marker='o',linestyle='') \n",
    "plt.plot(sources2['xcentroid']/2, phot_table2['scaled_ap_sum_bkgsub'], marker='+',linestyle='') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some statistics of the two sets of fluxes for comparison\n",
    "# get stddev from mean for each of the measurements in percentage\n",
    "\n",
    "photdata1 = phot_table['scaled_ap_sum_bkgsub']\n",
    "photdata2 = phot_table2['scaled_ap_sum_bkgsub']\n",
    "\n",
    "std1 = np.std(photdata1)\n",
    "mean1 = np.mean(photdata1)\n",
    "\n",
    "std2 = np.std(photdata2)\n",
    "mean2 = np.mean(photdata2)\n",
    "\n",
    "per1 = std1 / mean1 * 100\n",
    "per2 = std2 / mean2 * 100\n",
    "\n",
    "print('Mean and standard deviation of original scale data', mean1, std1)\n",
    "print('Mean and standard deviation of new scale data', mean2, std2)\n",
    "\n",
    "print('The standard deviation from the mean (as a percentage) for the original scale flux data, is', per1)\n",
    "print('The standard deviation from the mean (as a percentage) for the new scaled flux data, is', per2)\n",
    "\n",
    "# Compare stats on overall image values, not just phot values\n",
    "\n",
    "# im is the original scaled image and im2 is the rescaled image\n",
    "\n",
    "# print stats on original input image\n",
    "mean1, median1, std1 = sigma_clipped_stats(data, sigma=200.0, maxiters=5)  # default sigma=3\n",
    "print('Original image mean, median and std',mean1, median1, std1)\n",
    "\n",
    "# print stats on rescaled input image\n",
    "mean2, median2, std2 = sigma_clipped_stats(data2, sigma=200.0, maxiters=5)  # default sigma=3\n",
    "print('Rescaled image mean, median and std',mean2, median2, std2)\n",
    "\n",
    "ratio_mean = mean1 / mean2\n",
    "#ratio_median = median1 / median2\n",
    "\n",
    "print('The ratio of the mean of the two images is: ', ratio_mean)\n",
    "#print('The ratio of the median of the two images is: ', ratio_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing criteria\n",
    "If all RA/Dec matches have a 'pass' in the table for both original and scaled images, the fluxes for both the original data set and the scaled data set are roughly equal and the mean fluxes are nearly equivalent, then the notebook passes. The ratio printed of the means of the two images should be approximately 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about_ID\"></a>\n",
    "## About this Notebook\n",
    "**Author:** M. Cracraft, Senior Staff Scientist, INS/MIRI\n",
    "<br>**Updated On:** 04/02/2021 to add in testing the 'ratio' scaling option in resample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)\n",
    "<img style=\"float: right;\" src=\"./stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"stsci_pri_combo_mark_horizonal_white_bkgd\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
