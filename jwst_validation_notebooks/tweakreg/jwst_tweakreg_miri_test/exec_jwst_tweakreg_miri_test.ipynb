{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Testing Notebook: Calwebb_Image3, Tweakreg step with MIRI imaging\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: FGS, MIRI, NIRCam, NIRISS \n",
    "\n",
    "Tested on MIRI Simulated data\n",
    "\n",
    "### Table of Contents\n",
    "<div style=\"text-align: left\"> \n",
    "\n",
    "<br>  [Introduction](#intro_ID) <br> [Run JWST Pipelines](#pipeline_ID) <br> [Imports](#imports_ID) <br> [Create an association table for your cal files and run them through calwebb_image3](#runpipeline_ID) <br> [Find Stars in Image and Determine their Coordinates](#runscript_ID) <br> [Compare RA and Dec to expected Values](#residual_ID) <br> [About This Notebook](#about_ID) <br>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro_ID\"></a>\n",
    "# Introduction\n",
    "\n",
    "\n",
    "This test is designed to test the tweakreg step in the calwebb_image3 pipeline. At the start of the calwebb_image3 pipeline, the shifts between the images in an association table are found. This step creates image catalogs of point-like sources whose centroids are then used to compute corrections to the WCS of the input images such that sky catalogs obtained from the image catalogs using the corrected WCS will align on the sky.\n",
    "\n",
    "For more information on the pipeline step visit the links below. \n",
    "\n",
    "Step description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/tweakreg/README.html\n",
    "\n",
    "Pipeline code: https://github.com/spacetelescope/jwst/tree/master/jwst/tweakreg\n",
    "\n",
    "The data for this test were created with the MIRI Data Simulator, and the documentation for that code can be found here: http://miri.ster.kuleuven.be/bin/view/Public/MIRISim_Public\n",
    "\n",
    "\n",
    "### Calibration WG Requested Algorithm: \n",
    "\n",
    "A short description and link to the page: https://outerspace.stsci.edu/display/JWSTCC/Vanilla+Refine+WCS\n",
    "\n",
    "\n",
    "### Defining Terms\n",
    "Definition of terms or acronymns.\n",
    "\n",
    "JWST: James Webb Space Telescope\n",
    "\n",
    "MIRI: Mid-Infrared Instrument\n",
    "\n",
    "MIRISim: MIRI Data Simulator\n",
    "\n",
    "### Description of test\n",
    "\n",
    "This test is performed by creating a set of simulated data with multiple point sources located at specified coordinates. The simulator puts in the expected distortion, so the initial output data comes out of the simulator in distorted coordinates. When this data is then run through calwebb_detector1, calwebb_image2 and calwebbb_image3, the combined, undistorted image should have the point sources registered at the expected locations. In flight, this test can be repeated with known stars that should be found at their expected coordinates. If there is a shift in coordinates between the images that was not expected, tweakreg will find the sources to create a better image alignment. This is checked by using DAOStarFinder to find the point sources in each image (individual and combined) so that the catalogs can be compared to the expected RA and Dec values that were used to create the images. The user will look at whether the statistics of the combined sources are better or worse than those of the individual images.\n",
    "\n",
    "### Description of data\n",
    "\n",
    "The data used in this simulation were created with the MIRISim simulator.\n",
    "\n",
    "The simulation consists of eight files, two exposures each at four different dither positions. The images used in this test have 50 bright point sources scattered across the images, and were created in the F1130W filter.\n",
    "\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T17:32:15.036370Z",
     "iopub.status.busy": "2022-09-20T17:32:15.036105Z",
     "iopub.status.idle": "2022-09-20T17:32:15.043313Z",
     "shell.execute_reply": "2022-09-20T17:32:15.042867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRDS cache location: /tmp/crds_cache\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if 'CRDS_CACHE_TYPE' in os.environ:\n",
    "    if os.environ['CRDS_CACHE_TYPE'] == 'local':\n",
    "        os.environ['CRDS_PATH'] = os.path.join(os.environ['HOME'], 'crds', 'cache')\n",
    "    elif os.path.isdir(os.environ['CRDS_CACHE_TYPE']):\n",
    "        os.environ['CRDS_PATH'] = os.environ['CRDS_CACHE_TYPE']\n",
    "print('CRDS cache location: {}'.format(os.environ['CRDS_PATH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T17:32:15.045911Z",
     "iopub.status.busy": "2022-09-20T17:32:15.045725Z",
     "iopub.status.idle": "2022-09-20T17:32:17.069515Z",
     "shell.execute_reply": "2022-09-20T17:32:17.068826Z"
    }
   },
   "outputs": [],
   "source": [
    "# set up import statements\n",
    "from astropy.io import ascii, fits\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.table import Column\n",
    "from astropy.visualization import SqrtStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from astropy import table\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord, match_coordinates_sky\n",
    "\n",
    "#from ci_watson.artifactory_helpers import get_bigdata\n",
    "import glob\n",
    "from itertools import product\n",
    "from ci_watson.artifactory_helpers import get_bigdata\n",
    "\n",
    "# Box download imports \n",
    "from astropy.utils.data import download_file\n",
    "from pathlib import Path\n",
    "from shutil import move\n",
    "from os.path import splitext\n",
    "\n",
    "from jwst.datamodels import DrizProductModel, ImageModel\n",
    "from jwst.pipeline import Detector1Pipeline, Image2Pipeline, Image3Pipeline\n",
    "from jwst import associations\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base\n",
    "from jwst.associations import asn_from_list\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from photutils import CircularAperture, DAOStarFinder, CircularAnnulus, aperture_photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a temporary directory to work in and read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T17:32:17.073523Z",
     "iopub.status.busy": "2022-09-20T17:32:17.073162Z",
     "iopub.status.idle": "2022-09-20T17:32:17.077055Z",
     "shell.execute_reply": "2022-09-20T17:32:17.076500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TemporaryDirectory '/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/tmp/tmpdl7i7b7i'>\n"
     ]
    }
   ],
   "source": [
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "data_dir = TemporaryDirectory()\n",
    "os.chdir(data_dir.name)\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T17:32:17.079651Z",
     "iopub.status.busy": "2022-09-20T17:32:17.079239Z",
     "iopub.status.idle": "2022-09-20T17:32:17.082246Z",
     "shell.execute_reply": "2022-09-20T17:32:17.081807Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(\"Downloading input files\")\n",
    " \n",
    "#This readnoise file is needed for use with simulated data which has higher readnoise than actual data.\n",
    "#readnoise = get_bigdata('jwst_validation_notebooks',\n",
    "#                     'validation_data',\n",
    "#                     'jump',                     \n",
    "#                     'jump_miri_test', \n",
    "#                     'jwst_mirisim_readnoise.fits')\n",
    "\n",
    "#filelist = ['starfield_50star4ptdither_seq1_MIRIMAGE_F1130Wexp1.fits', \n",
    "#            'starfield_50star4ptdither_seq1_MIRIMAGE_F1130Wexp2.fits',\n",
    "#            'starfield_50star4ptdither_seq2_MIRIMAGE_F1130Wexp1.fits',\n",
    "#            'starfield_50star4ptdither_seq2_MIRIMAGE_F1130Wexp2.fits',\n",
    "#            'starfield_50star4ptdither_seq3_MIRIMAGE_F1130Wexp1.fits',\n",
    "#            'starfield_50star4ptdither_seq3_MIRIMAGE_F1130Wexp2.fits',\n",
    "#            'starfield_50star4ptdither_seq4_MIRIMAGE_F1130Wexp1.fits',\n",
    "#            'starfield_50star4ptdither_seq4_MIRIMAGE_F1130Wexp2.fits']\n",
    "\n",
    "#for file in filelist:\n",
    "#    input_file = get_bigdata('jwst_validation_notebooks',\n",
    "#                     'validation_data',\n",
    "#                     'outlier_detection',\n",
    "#                     'outlier_detection_miri_test',\n",
    "#                     file)\n",
    "    \n",
    "#coords = get_bigdata('jwst_validation_notebooks',\n",
    "#                     'validation_data',\n",
    "#                     'resample',\n",
    "#                     'resample_miri_test', \n",
    "#                     'radec_4ptdith_50star_mosaic_coords.txt')    \n",
    "\n",
    "#print(\"Finished Downloads\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T17:32:17.084644Z",
     "iopub.status.busy": "2022-09-20T17:32:17.084469Z",
     "iopub.status.idle": "2022-09-20T17:33:10.015318Z",
     "shell.execute_reply": "2022-09-20T17:33:10.014654Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read rate files in from Box rather than starting with uncal and running through calwebb_detector1\n",
    "\n",
    "def get_box_files(file_list):\n",
    "    for box_url,file_name in file_list:\n",
    "        if 'https' not in box_url:\n",
    "            box_url = 'https://stsci.box.com/shared/static/' + box_url\n",
    "        downloaded_file = download_file(box_url, timeout=600)\n",
    "        if Path(file_name).suffix == '':\n",
    "            ext = splitext(box_url)[1]\n",
    "            file_name += ext\n",
    "        move(downloaded_file, file_name)\n",
    "\n",
    "        \n",
    "file_urls = ['https://stsci.box.com/shared/static/46kwitm6fswmeiuw4gu6xxgeioy7dhca.fits',\n",
    "             'https://stsci.box.com/shared/static/8vs4njvio6y15cdcl3rjtb4veb55h6o9.fits',\n",
    "             'https://stsci.box.com/shared/static/09xjv0lpe35o50f2xf4ydu523g03s9fd.fits',\n",
    "             'https://stsci.box.com/shared/static/tqay5edhq1hstayk897ugd8t5sjbbjme.fits',\n",
    "             'https://stsci.box.com/shared/static/rmri5jb6gwpezva2rgzkkguoeos7nocv.fits',\n",
    "             'https://stsci.box.com/shared/static/pdtjm55j5ahj08i1rm91jw5p2ijpvi68.fits',\n",
    "             'https://stsci.box.com/shared/static/bw5jsrorue4g2eprpd06w8sdvy6etqhv.fits',\n",
    "             'https://stsci.box.com/shared/static/y3thiqwcyihw30vndpy16o8bjxn36o89.fits',\n",
    "             'https://stsci.box.com/shared/static/u2wc9ocug98ut8arz383oid0eru06qbo.txt']\n",
    "    \n",
    "file_names = ['starfield_50star4ptdither_seq1_MIRIMAGE_F1130Wexp1_rate.fits', \n",
    "            'starfield_50star4ptdither_seq1_MIRIMAGE_F1130Wexp2_rate.fits',\n",
    "            'starfield_50star4ptdither_seq2_MIRIMAGE_F1130Wexp1_rate.fits',\n",
    "            'starfield_50star4ptdither_seq2_MIRIMAGE_F1130Wexp2_rate.fits',\n",
    "            'starfield_50star4ptdither_seq3_MIRIMAGE_F1130Wexp1_rate.fits',\n",
    "            'starfield_50star4ptdither_seq3_MIRIMAGE_F1130Wexp2_rate.fits',\n",
    "            'starfield_50star4ptdither_seq4_MIRIMAGE_F1130Wexp1_rate.fits',\n",
    "            'starfield_50star4ptdither_seq4_MIRIMAGE_F1130Wexp2_rate.fits',\n",
    "            'radec_4ptdith_50star_mosaic_coords.txt']\n",
    "\n",
    "    \n",
    "box_download_list = [(url,name) for url,name in zip(file_urls,file_names)]\n",
    "\n",
    "\n",
    "get_box_files(box_download_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T17:33:10.019219Z",
     "iopub.status.busy": "2022-09-20T17:33:10.018747Z",
     "iopub.status.idle": "2022-09-20T17:33:10.022647Z",
     "shell.execute_reply": "2022-09-20T17:33:10.022014Z"
    }
   },
   "outputs": [],
   "source": [
    "coords = 'radec_4ptdith_50star_mosaic_coords.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the calwebb_detector1 pipeline to get rate.fits files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T17:33:10.025373Z",
     "iopub.status.busy": "2022-09-20T17:33:10.024879Z",
     "iopub.status.idle": "2022-09-20T17:33:10.028352Z",
     "shell.execute_reply": "2022-09-20T17:33:10.027754Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run the calwebb_detector1 pipeline\n",
    "\n",
    "# set up pipeline parameters \n",
    "#rej_thresh=10.0  # rejection threshold for jump step\n",
    "\n",
    "#print('There are ', len(filelist), ' images.')\n",
    "    \n",
    "#slopelist = []    \n",
    "    \n",
    "# loop over list of files\n",
    "#for file in filelist:\n",
    "       \n",
    "    # set up pipeline parameters for input\n",
    "#    pipe1 = Detector1Pipeline()\n",
    "#    pipe1.jump.rejection_threshold = rej_thresh\n",
    "#    pipe1.jump.override_readnoise = readnoise\n",
    "#    pipe1.ramp_fit.override_readnoise = readnoise\n",
    "\n",
    "#    pipe1.refpix.skip = True  # needs update to simulator for this to work properly with simulated data\n",
    "        \n",
    "    # set up output file name\n",
    "#    base, remainder = file.split('.')\n",
    "#    outname = base\n",
    "        \n",
    "#    pipe1.jump.output_file = outname+'.fits'    \n",
    "    #pipe1.ramp_fit.output_file = outname+'.fits'\n",
    "#    pipe1.output_file = outname+'.fits'\n",
    "\n",
    "    # Run pipeline on each file\n",
    "#    rampfile = pipe1.run(file)\n",
    "#    slopelist.append(rampfile)\n",
    "    \n",
    "    # Close the input files\n",
    "    #file.close()\n",
    "\n",
    "#print('Detector 1 steps completed on all files.')\n",
    "#print(slopelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T17:33:10.030770Z",
     "iopub.status.busy": "2022-09-20T17:33:10.030284Z",
     "iopub.status.idle": "2022-09-20T17:33:10.033395Z",
     "shell.execute_reply": "2022-09-20T17:33:10.032943Z"
    }
   },
   "outputs": [],
   "source": [
    "slopelist = ['starfield_50star4ptdither_seq1_MIRIMAGE_F1130Wexp1_rate.fits', \n",
    "            'starfield_50star4ptdither_seq1_MIRIMAGE_F1130Wexp2_rate.fits',\n",
    "            'starfield_50star4ptdither_seq2_MIRIMAGE_F1130Wexp1_rate.fits',\n",
    "            'starfield_50star4ptdither_seq2_MIRIMAGE_F1130Wexp2_rate.fits',\n",
    "            'starfield_50star4ptdither_seq3_MIRIMAGE_F1130Wexp1_rate.fits',\n",
    "            'starfield_50star4ptdither_seq3_MIRIMAGE_F1130Wexp2_rate.fits',\n",
    "            'starfield_50star4ptdither_seq4_MIRIMAGE_F1130Wexp1_rate.fits',\n",
    "            'starfield_50star4ptdither_seq4_MIRIMAGE_F1130Wexp2_rate.fits']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run calwebb_image2 pipeline to create cal.fits files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T17:33:10.035738Z",
     "iopub.status.busy": "2022-09-20T17:33:10.035341Z",
     "iopub.status.idle": "2022-09-20T17:33:12.896935Z",
     "shell.execute_reply": "2022-09-20T17:33:12.895721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  8  images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:33:11,066 - stpipe.Image2Pipeline - INFO - Image2Pipeline instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:33:11,068 - stpipe.Image2Pipeline.bkg_subtract - INFO - BackgroundStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:33:11,070 - stpipe.Image2Pipeline.assign_wcs - INFO - AssignWcsStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:33:11,071 - stpipe.Image2Pipeline.flat_field - INFO - FlatFieldStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:33:11,072 - stpipe.Image2Pipeline.photom - INFO - PhotomStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:33:11,074 - stpipe.Image2Pipeline.resample - INFO - ResampleStep instance created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:33:11,184 - stpipe.Image2Pipeline - INFO - Step Image2Pipeline running with args (<ImageModel(1024, 1032) from starfield_50star4ptdither_seq1_MIRIMAGE_F1130Wexp1_rate.fits>,).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:33:11,189 - stpipe.Image2Pipeline - INFO - Step Image2Pipeline parameters are: {'pre_hooks': [], 'post_hooks': [], 'output_file': '/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/tmp/tmpdl7i7b7i/starfield_50star4ptdither_seq1_MIRIMAGE_F1130Wexp1_rate.fits_cal.fits', 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': True, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'save_bsub': False, 'steps': {'bkg_subtract': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'save_combined_background': False, 'sigma': 3.0, 'maxiters': None, 'wfss_mmag_extract': None}, 'assign_wcs': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'sip_approx': True, 'sip_max_pix_error': 0.25, 'sip_degree': None, 'sip_max_inv_pix_error': 0.25, 'sip_inv_degree': None, 'sip_npoints': 32, 'slit_y_low': -0.55, 'slit_y_high': 0.55}, 'flat_field': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'save_interpolated_flat': False, 'user_supplied_flat': None, 'inverse': False}, 'photom': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'inverse': False, 'source_type': None}, 'resample': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': True, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'pixfrac': 1.0, 'kernel': 'square', 'fillval': 'INDEF', 'weight_type': 'ivm', 'output_shape': None, 'crpix': None, 'crval': None, 'rotation': None, 'pixel_scale_ratio': 1.0, 'pixel_scale': None, 'single': False, 'blendheaders': True, 'allowed_memory': None, 'in_memory': True}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:33:11,197 - stpipe.Image2Pipeline - INFO - Prefetching reference files for dataset: 'starfield_50star4ptdither_seq1_MIRIMAGE_F1130Wexp1_rate.fits' reftypes = ['area', 'camera', 'collimator', 'dflat', 'disperser', 'distortion', 'drizpars', 'fflat', 'filteroffset', 'flat', 'fore', 'fpa', 'ifufore', 'ifupost', 'ifuslicer', 'msa', 'ote', 'photom', 'regions', 'sflat', 'specwcs', 'wavelengthrange', 'wfssbkg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 13:33:11,316 - CRDS - INFO -  Fetching  /tmp/crds_cache/mappings/jwst/jwst_nirspec_superbias_0051.rmap   26.4 K bytes  (1 / 13 files) (0 / 124.3 K bytes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py\", line 347, in local_bestrefs\n",
      "    return hv_best_references(context, parameters, reftypes)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py\", line 367, in hv_best_references\n",
      "    ctx = get_symbolic_mapping(context_file, cached=True)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py\", line 670, in get_symbolic_mapping\n",
      "    return get_pickled_mapping(   # reviewed\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py\", line 306, in __call__\n",
      "    key, result = self._readonly(*args, **keys)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py\", line 293, in _readonly\n",
      "    return key, self.uncached(*args, **keys)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py\", line 695, in get_pickled_mapping\n",
      "    loaded = rmap.asmapping(mapping, cached=cached, **keys)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/rmap.py\", line 1665, in asmapping\n",
      "    return get_cached_mapping(filename_or_mapping, **keys)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/rmap.py\", line 1592, in get_cached_mapping\n",
      "    return _load_mapping(mapping, **keys)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py\", line 306, in __call__\n",
      "    key, result = self._readonly(*args, **keys)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py\", line 293, in _readonly\n",
      "    return key, self.uncached(*args, **keys)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/rmap.py\", line 1643, in _load_mapping\n",
      "    return cls.from_file(mapping, **keys)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/rmap.py\", line 266, in from_file\n",
      "    text = utils.get_uri_content(filename)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py\", line 737, in get_uri_content\n",
      "    with open(uri, mode) as file:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/crds_cache/mappings/jwst/jwst_0982.pmap'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py\", line 653, in download\n",
      "    return proxy.apply_with_retries(self.download_core, name, localpath)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/proxy.py\", line 50, in apply_with_retries\n",
      "    raise exc2\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/proxy.py\", line 44, in apply_with_retries\n",
      "    return func(*pars, **keys)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py\", line 679, in download_core\n",
      "    self.generator_download(generator, localpath)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py\", line 684, in generator_download\n",
      "    with open(localpath, \"wb+\") as outfile:\n",
      "OSError: [Errno 28] No space left on device: '/tmp/crds_cache/mappings/jwst/jwst_nirspec_superbias_0051.rmap'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py\", line 351, in local_bestrefs\n",
      "    api.dump_mappings(context, ignore_cache=ignore_cache)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py\", line 778, in dump_mappings\n",
      "    return dump_mappings3(*args, **keys)[0]\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py\", line 771, in dump_mappings3\n",
      "    return FileCacher(pipeline_context, ignore_cache, raise_exceptions).get_local_files(mappings)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py\", line 594, in get_local_files\n",
      "    n_bytes = self.download_files(downloads, localpaths)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py\", line 634, in download_files\n",
      "    self.download(name, path)\n",
      "  File \"/internal/data1/jenkins/workspace/Notebooks/jwst_validation_notebooks_spacetelescope/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py\", line 656, in download\n",
      "    raise CrdsDownloadError(\n",
      "crds.core.exceptions.CrdsDownloadError: Error fetching data for 'jwst_nirspec_superbias_0051.rmap' at CRDS server 'https://jwst-crds.stsci.edu' with mode 'http' : [Errno 28] No space left on device: '/tmp/crds_cache/mappings/jwst/jwst_nirspec_superbias_0051.rmap'\n"
     ]
    },
    {
     "ename": "CrdsDownloadError",
     "evalue": "Failed caching mapping files: Error fetching data for 'jwst_nirspec_superbias_0051.rmap' at CRDS server 'https://jwst-crds.stsci.edu' with mode 'http' : [Errno 28] No space left on device: '/tmp/crds_cache/mappings/jwst/jwst_nirspec_superbias_0051.rmap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py:347\u001b[0m, in \u001b[0;36mlocal_bestrefs\u001b[0;34m(parameters, reftypes, context, ignore_cache)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;66;03m# Finally do the best refs computation using pmap methods from local code.\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhv_best_references\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreftypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py:367\u001b[0m, in \u001b[0;36mhv_best_references\u001b[0;34m(context_file, header, include, condition)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m\"\"\"Compute the best references for `header` for the given CRDS\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m`context_file`.   This is a local computation using local rmaps and\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03mCPU resources.   If `include` is None,  return results for all\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03mfilekinds appropriate to `header`,  otherwise return only those\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03mfilekinds listed in `include`.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m ctx \u001b[38;5;241m=\u001b[39m \u001b[43mget_symbolic_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m conditioned \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcondition_header(header) \u001b[38;5;28;01mif\u001b[39;00m condition \u001b[38;5;28;01melse\u001b[39;00m header\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py:670\u001b[0m, in \u001b[0;36mget_symbolic_mapping\u001b[0;34m(mapping, observatory, cached, use_pickles, save_pickles, **keys)\u001b[0m\n\u001b[1;32m    669\u001b[0m abs_mapping \u001b[38;5;241m=\u001b[39m translate_date_based_context(mapping, observatory)\n\u001b[0;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_pickled_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# reviewed\u001b[39;49;00m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mabs_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcached\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pickles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_pickles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_pickles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_pickles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py:306\u001b[0m, in \u001b[0;36mCachedFunction.__call__\u001b[0;34m(self, *args, **keys)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03m\"\"\"Compute or fetch func(*args, **keys).  Add the result to the cache.\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03mreturn func(*args, **keys)\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m key, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readonly\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache[key] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py:293\u001b[0m, in \u001b[0;36mCachedFunction._readonly\u001b[0;34m(self, *args, **keys)\u001b[0m\n\u001b[1;32m    292\u001b[0m log\u001b[38;5;241m.\u001b[39mverbose(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncached call\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muncached\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mrepr\u001b[39m(key), verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m key, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muncached\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py:695\u001b[0m, in \u001b[0;36mget_pickled_mapping\u001b[0;34m(mapping, cached, use_pickles, save_pickles, **keys)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43mrmap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masmapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcached\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loaded\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/rmap.py:1665\u001b[0m, in \u001b[0;36masmapping\u001b[0;34m(filename_or_mapping, cached, **keys)\u001b[0m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cached \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcached\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m-> 1665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_cached_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cached \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreadonly\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/rmap.py:1592\u001b[0m, in \u001b[0;36mget_cached_mapping\u001b[0;34m(mapping, **keys)\u001b[0m\n\u001b[1;32m   1591\u001b[0m keys[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloader\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m get_cached_mapping\n\u001b[0;32m-> 1592\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py:306\u001b[0m, in \u001b[0;36mCachedFunction.__call__\u001b[0;34m(self, *args, **keys)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03m\"\"\"Compute or fetch func(*args, **keys).  Add the result to the cache.\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03mreturn func(*args, **keys)\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m key, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readonly\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache[key] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py:293\u001b[0m, in \u001b[0;36mCachedFunction._readonly\u001b[0;34m(self, *args, **keys)\u001b[0m\n\u001b[1;32m    292\u001b[0m log\u001b[38;5;241m.\u001b[39mverbose(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncached call\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muncached\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mrepr\u001b[39m(key), verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m key, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muncached\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/rmap.py:1643\u001b[0m, in \u001b[0;36m_load_mapping\u001b[0;34m(mapping, **keys)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/rmap.py:266\u001b[0m, in \u001b[0;36mMapping.from_file\u001b[0;34m(cls, basename, *args, **keys)\u001b[0m\n\u001b[1;32m    265\u001b[0m     filename \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mlocate_mapping(basename)\n\u001b[0;32m--> 266\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_uri_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_string(text, basename, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkeys)\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/utils.py:737\u001b[0m, in \u001b[0;36mget_uri_content\u001b[0;34m(uri, mode)\u001b[0m\n\u001b[1;32m    736\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (mode\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 737\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/crds_cache/mappings/jwst/jwst_0982.pmap'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py:653\u001b[0m, in \u001b[0;36mFileCacher.download\u001b[0;34m(self, name, localpath)\u001b[0m\n\u001b[1;32m    652\u001b[0m     utils\u001b[38;5;241m.\u001b[39mensure_dir_exists(localpath)\n\u001b[0;32m--> 653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mproxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_retries\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_core\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocalpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/proxy.py:50\u001b[0m, in \u001b[0;36mapply_with_retries\u001b[0;34m(func, *pars, **keys)\u001b[0m\n\u001b[1;32m     49\u001b[0m         exc2 \u001b[38;5;241m=\u001b[39m exc\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc2\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/proxy.py:44\u001b[0m, in \u001b[0;36mapply_with_retries\u001b[0;34m(func, *pars, **keys)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py:679\u001b[0m, in \u001b[0;36mFileCacher.download_core\u001b[0;34m(self, name, localpath)\u001b[0m\n\u001b[1;32m    678\u001b[0m     generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_data_http(name)\n\u001b[0;32m--> 679\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocalpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_file(name, localpath)\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py:684\u001b[0m, in \u001b[0;36mFileCacher.generator_download\u001b[0;34m(self, generator, localpath)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;124;03m\"\"\"Read all bytes from `generator` until file is downloaded to `localpath.`\"\"\"\u001b[39;00m\n\u001b[0;32m--> 684\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlocalpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m outfile:\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m generator:\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device: '/tmp/crds_cache/mappings/jwst/jwst_nirspec_superbias_0051.rmap'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mCrdsDownloadError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py:351\u001b[0m, in \u001b[0;36mlocal_bestrefs\u001b[0;34m(parameters, reftypes, context, ignore_cache)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 351\u001b[0m     \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump_mappings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CrdsError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py:778\u001b[0m, in \u001b[0;36mdump_mappings\u001b[0;34m(*args, **keys)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;124;03m\"\"\"See dump_mappings3.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \n\u001b[1;32m    776\u001b[0m \u001b[38;5;124;03mReturns { mapping_basename :   mapping_local_filepath ... }\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdump_mappings3\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py:771\u001b[0m, in \u001b[0;36mdump_mappings3\u001b[0;34m(pipeline_context, ignore_cache, mappings, raise_exceptions)\u001b[0m\n\u001b[1;32m    770\u001b[0m mappings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(mappings))))\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFileCacher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_local_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmappings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py:594\u001b[0m, in \u001b[0;36mFileCacher.get_local_files\u001b[0;34m(self, names)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m downloads:\n\u001b[0;32m--> 594\u001b[0m     n_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownloads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocalpaths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py:634\u001b[0m, in \u001b[0;36mFileCacher.download_files\u001b[0;34m(self, downloads, localpaths)\u001b[0m\n\u001b[1;32m    633\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(file_progress(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, path, \u001b[38;5;28mbytes\u001b[39m, bytes_so_far, total_bytes, nth_file, total_files))\n\u001b[0;32m--> 634\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m bytes_so_far \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(path)\u001b[38;5;241m.\u001b[39mst_size\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/client/api.py:656\u001b[0m, in \u001b[0;36mFileCacher.download\u001b[0;34m(self, name, localpath)\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_file(localpath)\n\u001b[0;32m--> 656\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CrdsDownloadError(\n\u001b[1;32m    657\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError fetching data for\u001b[39m\u001b[38;5;124m\"\u001b[39m, srepr(name),\n\u001b[1;32m    658\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mat CRDS server\u001b[39m\u001b[38;5;124m\"\u001b[39m, srepr(get_crds_server()),\n\u001b[1;32m    659\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith mode\u001b[39m\u001b[38;5;124m\"\u001b[39m, srepr(config\u001b[38;5;241m.\u001b[39mget_download_mode()),\n\u001b[1;32m    660\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(exc)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:  \u001b[38;5;66;03m#  mainly for control-c,  catch it and throw it.\u001b[39;00m\n",
      "\u001b[0;31mCrdsDownloadError\u001b[0m: Error fetching data for 'jwst_nirspec_superbias_0051.rmap' at CRDS server 'https://jwst-crds.stsci.edu' with mode 'http' : [Errno 28] No space left on device: '/tmp/crds_cache/mappings/jwst/jwst_nirspec_superbias_0051.rmap'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mCrdsDownloadError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     pipe2\u001b[38;5;241m.\u001b[39mresample\u001b[38;5;241m.\u001b[39msave_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     pipe2\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     calfile \u001b[38;5;241m=\u001b[39m \u001b[43mpipe2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrampfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     callist\u001b[38;5;241m.\u001b[39mappend(calfile)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(callist)\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/stpipe/step.py:481\u001b[0m, in \u001b[0;36mStep.run\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefetch_references:\n\u001b[0;32m--> 481\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m         step_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/stpipe/step.py:598\u001b[0m, in \u001b[0;36mStep.prefetch\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;66;03m# prefetch truly occurs at the Pipeline (or subclass) level.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_file_types) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip:\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_precache_references\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/stpipe/pipeline.py:313\u001b[0m, in \u001b[0;36mPipeline._precache_references\u001b[0;34m(self, input_file)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen_model(input_file, asn_n_members\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    312\u001b[0m                         asn_exptypes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscience\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mas\u001b[39;00m model:\n\u001b[0;32m--> 313\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_precache_references_opened\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mIOError\u001b[39;00m):\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirst argument \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m does not appear to be a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(input_file))\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/stpipe/pipeline.py:336\u001b[0m, in \u001b[0;36mPipeline._precache_references_opened\u001b[0;34m(self, model_or_container)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_precache_references_opened(contained_model)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;66;03m# precache a single model object\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_precache_references_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_or_container\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/stpipe/pipeline.py:360\u001b[0m, in \u001b[0;36mPipeline._precache_references_impl\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    356\u001b[0m fetch_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_file_types) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(ovr_refs\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrefetching reference files for dataset: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mrepr\u001b[39m(model\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mfilename) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    359\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m reftypes = \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mrepr\u001b[39m(fetch_types))\n\u001b[0;32m--> 360\u001b[0m crds_refs \u001b[38;5;241m=\u001b[39m \u001b[43mcrds_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_multiple_reference_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_crds_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrds_observatory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m ref_path_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(crds_refs\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(ovr_refs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (reftype, refpath) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(ref_path_map\u001b[38;5;241m.\u001b[39mitems()):\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/stpipe/crds_client.py:55\u001b[0m, in \u001b[0;36mget_multiple_reference_paths\u001b[0;34m(parameters, reference_file_types, observatory)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst argument must be a dict of parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m log\u001b[38;5;241m.\u001b[39mset_log_time(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 55\u001b[0m refpaths \u001b[38;5;241m=\u001b[39m \u001b[43m_get_refpaths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreference_file_types\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservatory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m refpaths\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/stpipe/crds_client.py:68\u001b[0m, in \u001b[0;36m_get_refpaths\u001b[0;34m(data_dict, reference_file_types, observatory)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m crds_cache_locking\u001b[38;5;241m.\u001b[39mget_cache_lock():\n\u001b[0;32m---> 68\u001b[0m     bestrefs \u001b[38;5;241m=\u001b[39m \u001b[43mcrds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetreferences\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreftypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference_file_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservatory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobservatory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m refpaths \u001b[38;5;241m=\u001b[39m {filetype: filepath \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m filepath\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m (filetype, filepath) \u001b[38;5;129;01min\u001b[39;00m bestrefs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m refpaths\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py:122\u001b[0m, in \u001b[0;36mgetreferences\u001b[0;34m(parameters, reftypes, context, ignore_cache, observatory, fast)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetreferences\u001b[39m(parameters, reftypes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ignore_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     82\u001b[0m                   observatory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjwst\u001b[39m\u001b[38;5;124m\"\u001b[39m, fast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    This is the top-level get reference call for all of CRDS.  Based on\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    `parameters`, getreferences() will download/cache the corresponding best\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m      cached reference file.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     final_context, bestrefs \u001b[38;5;241m=\u001b[39m \u001b[43m_initial_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgetreferences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreftypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservatory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfast\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# Attempt to cache the recommended references,  which unlike dump_mappings\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# should work without network access if files are already cached.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     best_refs_paths \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mcache_references(\n\u001b[1;32m    128\u001b[0m         final_context, bestrefs, ignore_cache\u001b[38;5;241m=\u001b[39mignore_cache)\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py:209\u001b[0m, in \u001b[0;36m_initial_recommendations\u001b[0;34m(name, parameters, reftypes, context, ignore_cache, observatory, fast)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    208\u001b[0m     log\u001b[38;5;241m.\u001b[39mverbose(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing best references locally.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 209\u001b[0m     bestrefs \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_bestrefs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreftypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreftypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m     log\u001b[38;5;241m.\u001b[39mverbose(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing best references remotely.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/jwst_validation_notebooks/lib/python3.9/site-packages/crds/core/heavy_client.py:354\u001b[0m, in \u001b[0;36mlocal_bestrefs\u001b[0;34m(parameters, reftypes, context, ignore_cache)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CrdsError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    353\u001b[0m     traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CrdsDownloadError(\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed caching mapping files:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(exc)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hv_best_references(context, parameters, reftypes)\n",
      "\u001b[0;31mCrdsDownloadError\u001b[0m: Failed caching mapping files: Error fetching data for 'jwst_nirspec_superbias_0051.rmap' at CRDS server 'https://jwst-crds.stsci.edu' with mode 'http' : [Errno 28] No space left on device: '/tmp/crds_cache/mappings/jwst/jwst_nirspec_superbias_0051.rmap'"
     ]
    }
   ],
   "source": [
    "# Run Calwebb_image2 on output files from detector1\n",
    "    \n",
    "print('There are ', len(slopelist), ' images.')\n",
    "\n",
    "callist = []\n",
    "ratefilenames = []\n",
    "\n",
    "# cycle through files\n",
    "for file in slopelist:\n",
    "    rampfile = ImageModel(file)\n",
    "    \n",
    "    # create an object for the pipeline    \n",
    "    pipe2 = Image2Pipeline()\n",
    "    \n",
    "    filename = rampfile.meta.filename\n",
    "    ratefilenames.append(filename)\n",
    "    # Set pipeline parameters\n",
    "\n",
    "    pipe2.save_results = True\n",
    "    pipe2.output_file = filename +'_cal.fits'\n",
    "    pipe2.resample.save_results = True\n",
    "    pipe2.suffix = None\n",
    "\n",
    "    calfile = pipe2.run(rampfile)\n",
    "\n",
    "    callist.append(calfile)\n",
    "\n",
    "print(callist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagelist = [ele.replace('rate', 'cal') for ele in ratefilenames]\n",
    "print(imagelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test # 1: See what happens with tweakreg when given data with no shifts.\n",
    "\n",
    "This test uses MIRISim data using only the simulated dithers, and no shifts. Two exposures each of four different dithers, perfect alignment. \n",
    "\n",
    "First look at the cal images out of calwebb_image2. \n",
    "* Use DAOStarFinder to get the x,y positions of the stars in each image\n",
    "* Use wcs info from image to convert x,y positions to RA, Dec\n",
    "* Compare the RA, Dec calculated values to the RA, Dec positions put into the simulated images\n",
    "* Get statistics on the differences of the calculated and input positions in units of mas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find stars and get RA, Dec from *_cal.fits files\n",
    "\n",
    "# Run DAOStarFinder to find sources in image\n",
    "allRAdiff_cal = []\n",
    "allDecdiff_cal = []\n",
    "\n",
    "for calimage in imagelist:\n",
    "    image = ImageModel(calimage)\n",
    "    \n",
    "    # pull out data portion of input file\n",
    "    data = image.data\n",
    "    \n",
    "    # print stats on input image\n",
    "    print(calimage)\n",
    "    mean, median, std = sigma_clipped_stats(data, sigma=200.0, maxiters=5)  # default sigma=3\n",
    "    print('Image mean, median and std',mean, median, std)\n",
    "\n",
    "    ap_radius = 5.  # radius for aperture for centroiding and photometry\n",
    "\n",
    "    daofind = DAOStarFinder(fwhm=3.0, threshold=10.*std)    # default threshold=5*std, fwhm=3\n",
    "    sources = daofind(data)     \n",
    "\n",
    "    # Create apertures for x,y positions\n",
    "    positions = tuple(zip(sources['xcentroid'], sources['ycentroid']))\n",
    "    #print(positions)\n",
    "\n",
    "    #positions = (sources['xcentroid'], sources['ycentroid'])\n",
    "    apertures = CircularAperture(positions, r=ap_radius)\n",
    "    \n",
    "    # using wcs info from images, put coordinates into RA, Dec\n",
    "    ra, dec = image.meta.wcs(sources['xcentroid'], sources['ycentroid'])\n",
    "\n",
    "    # add RA, Dec to sources table\n",
    "\n",
    "    ra_col = Column(name='RA', data=ra)\n",
    "    dec_col = Column(name='Dec', data=dec)\n",
    "    sources.add_column(ra_col)\n",
    "    sources.add_column(dec_col)\n",
    "\n",
    "    # print RA, Dec for each x, y position found\n",
    "    #print(sources['xcentroid', 'ycentroid', 'RA', 'Dec'])  \n",
    "\n",
    "    sources_sub = sources['xcentroid', 'ycentroid', 'RA', 'Dec']\n",
    "    sources_sub.pprint_all()\n",
    "    print()\n",
    "    \n",
    "    # read in text file with RA and Dec input coordinates\n",
    "    RA_in, Dec_in = np.loadtxt( coords, dtype=str, unpack=True)\n",
    "\n",
    "    # put RA and Dec into floats\n",
    "    RA_sim = RA_in.astype(float)\n",
    "    Dec_sim = Dec_in.astype(float)\n",
    "    \n",
    "    # Put ra, dec coords into a table\n",
    "    cat1_sim = Table([RA_sim, Dec_sim], names=('ra', 'dec'))\n",
    "    cat2_calc = Table([ra, dec], names=('ra', 'dec'))\n",
    "    \n",
    "    # Get coordinates with SkyCoord for each catalog\n",
    "    \n",
    "    coord_cat1_sim = SkyCoord(ra=cat1_sim['ra'], dec=cat1_sim['dec'], unit=\"deg\")\n",
    "    coord_cat2_calc = SkyCoord(ra=cat2_calc['ra'], dec=cat2_calc['dec'], unit=\"deg\")\n",
    "    ind_cat2_cat1, dist_2d, _ = match_coordinates_sky(coord_cat1_sim, coord_cat2_calc)\n",
    "    \n",
    "    # Find where the catalogs match\n",
    "    \n",
    "    cat1_matched = cat1_sim[dist_2d.arcsec<0.05]\n",
    "    cat2_matched = cat2_calc[ind_cat2_cat1[dist_2d.arcsec<0.05]]\n",
    "    \n",
    "    #print(cat1_matched)\n",
    "    \n",
    "    # Get differences in RA, Dec\n",
    "    ra_diff = cat2_matched['ra'] - cat1_matched['ra']\n",
    "    dec_diff = cat2_matched['dec'] - cat1_matched['dec'] \n",
    "    \n",
    "    #print(ra_diff)\n",
    "    \n",
    "    # put differences in milliarcseconds\n",
    "    ra_diff = ra_diff * 3600000\n",
    "    dec_diff = dec_diff * 3600000\n",
    "    \n",
    "    \n",
    "    # Compare input RA, Dec to found RA, Dec\n",
    "    print('RA_Diff (mas)  Dec_diff (mas) pass/fail')\n",
    "    # Find if the differences are within the allowed 30 mas range\n",
    "    for i in np.arange(0,len(ra_diff)):\n",
    "        #if ra_diff[i] < 30 and dec_diff[i] < 30:\n",
    "        allRAdiff_cal.append(ra_diff[i])\n",
    "        allDecdiff_cal.append(dec_diff[i])\n",
    "        if abs(ra_diff[i]) < 30 and abs(dec_diff[i]) < 30: \n",
    "            test = 'pass' \n",
    "        else: \n",
    "            test = 'fail'\n",
    "        print('{:15.6f} {:15.6f} {}'.format(ra_diff[i], dec_diff[i], test))\n",
    " \n",
    "    \n",
    "    # Plot ra and dec differences\n",
    "    plt.title ('Differences in RA and Dec in milliarcseconds')\n",
    "    plt.ylabel('Delta RA')\n",
    "    plt.xlabel('Delta Dec')\n",
    "    plt.scatter(ra_diff,dec_diff)\n",
    "    plt.show()\n",
    " \n",
    "    # Plot should show no differences greater than 30 milliarcseconds  \n",
    "    \n",
    "meanRAdiff_cal, medianRAdiff_cal, stdRAdiff_cal = sigma_clipped_stats(allRAdiff_cal, sigma=5.0, maxiters=5)  # default sigma=3\n",
    "meanDecdiff_cal, medianDecdiff_cal, stdDecdiff_cal = sigma_clipped_stats(allDecdiff_cal, sigma=5.0, maxiters=5)  # default sigma=3\n",
    "\n",
    "print('RA difference mean, median and std (units in mas)',meanRAdiff_cal, medianRAdiff_cal, stdRAdiff_cal) \n",
    "print('Dec difference mean, median and std (units in mas)',meanDecdiff_cal, medianDecdiff_cal, stdDecdiff_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the images through calwebb_image3 with tweakreg on\n",
    "\n",
    "Alter any parameters needed to get better results from tweakreg. Look at individual i2d images afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use asn_from_list to create association table\n",
    "\n",
    "#calfiles = glob.glob('starfield*_cal.fits')\n",
    "asn = asn_from_list.asn_from_list(imagelist, rule=DMS_Level3_Base, product_name='starfield_50star4ptdither_combined.fits')\n",
    "\n",
    "# use this if you need to add non'science' exposure types\n",
    "#asn['products'][0]['members'][1]['exptype'] = 'background'\n",
    "#asn['products'][0]['members'][2]['exptype'] = 'sourcecat'\n",
    "\n",
    "# dump association table to a .json file for use in image3\n",
    "with open('starfield_50star4ptdither_asnfile.json', 'w') as fp:\n",
    "    fp.write(asn.dump()[1])\n",
    "\n",
    "print(asn)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Calwebb_image3 on the association table with tweakreg on\n",
    "    \n",
    "# set any specific parameters\n",
    "# tweakreg parameters to allow data to run\n",
    "fwhm = 3.318 #3.27  # Gaussian kernel FWHM of objects expected, default=2.5\n",
    "minobj = 5  # minimum number of objects needed to match positions for a good fit, default=15\n",
    "snr = 40 # signal to noise threshold, default=5\n",
    "sigma = 3 # clipping limit, in sigma units, used when performing fit, default=3\n",
    "fit_geom ='rshift' # ftype of affine transformation to be considered when fitting catalogs, default='general'\n",
    "use2dhist = False  # boolean indicating whether to use 2D histogram to find initial offset, default=True\n",
    "   \n",
    "pipe3=Image3Pipeline()    \n",
    "pipe3.tweakreg.kernel_fwhm = fwhm\n",
    "pipe3.tweakreg.snr_threshold = snr\n",
    "pipe3.tweakreg.minobj = minobj\n",
    "pipe3.tweakreg.sigma = sigma\n",
    "pipe3.tweakreg.fitgeometry = fit_geom\n",
    "pipe3.tweakreg.use2dhist = use2dhist\n",
    "pipe3.tweakreg.save_catalogs = True\n",
    "#pipe3.tweakreg.skip = True        # test to see if this affects the final output\n",
    "pipe3.outlier_detection.skip = True # this is set in later step so mis-alignments aren't 'hidden'\n",
    "pipe3.outlier_detection.skip = True\n",
    "pipe3.source_catalog.save_results = True\n",
    "pipe3.save_results = True\n",
    "#pipe3.output_dir = datadir\n",
    "\n",
    "# run Image3\n",
    "\n",
    "#im = pipe3.run(rtdata.input)\n",
    "image = pipe3.run('starfield_50star4ptdither_asnfile.json')\n",
    "print('Image 3 pipeline finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go through list of individual images and see which sources were found for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of catalogs\n",
    "\n",
    "cataloglist = [ele.replace('cal.fits', 'cal_cat.ecsv') for ele in imagelist]\n",
    "print(imagelist)\n",
    "print()\n",
    "print(cataloglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each image and overplot the sources found in the individual catalogs\n",
    "\n",
    "index=0\n",
    "for cal_image in imagelist:\n",
    "    indimage = ImageModel(cal_image)\n",
    "    ind_data = indimage.data\n",
    "    \n",
    "    indcat = cataloglist[index]\n",
    "    catdata = table.Table.read(indcat, format='ascii', comment='#')\n",
    "    print(cal_image)\n",
    "    print(indcat)\n",
    "    print(len(catdata['xcentroid']), 'sources found')\n",
    "    \n",
    "    # mark sources on image frame to see if the correct sources were found\n",
    "    norm = ImageNormalize(stretch=SqrtStretch())\n",
    "    # keep image stretch in mind for plotting. sky subtracted range ~ (-15, 10), single sample ~ (0, 20)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(ind_data, cmap='Greys', origin='lower', vmin=0,vmax=50)#, norm=norm)\n",
    "    plt.scatter(catdata['xcentroid'], catdata['ycentroid'],lw=1, s=20,color='red')\n",
    "    plt.show()\n",
    "    index = index+1\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get position differences as found earlier for the individual i2d files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find stars and get RA, Dec from *_i2d.fits files\n",
    "\n",
    "#datadir = '/ifs/jwst/wit/miri/pipelinetests/cracraft/build7_8/'\n",
    "#filelist = 'starfield_50star4ptdither_i2dfiles.txt'\n",
    "filelist = glob.glob('*exp*i2d.fits')\n",
    "print(filelist)\n",
    "print()\n",
    "\n",
    "# Run DAOStarFinder to find sources in image\n",
    "allRAdiff_i2d = []\n",
    "allDecdiff_i2d = []\n",
    "\n",
    "for i2dimage in filelist:\n",
    "    image = ImageModel(i2dimage)\n",
    "    \n",
    "    # pull out data portion of input file\n",
    "    data = image.data\n",
    "    \n",
    "    # print stats on input image\n",
    "    print(i2dimage)\n",
    "    mean, median, std = sigma_clipped_stats(data, sigma=200.0, maxiters=5)  # default sigma=3\n",
    "    print('Image mean, median and std',mean, median, std)\n",
    "\n",
    "    ap_radius = 5.  # radius for aperture for centroiding and photometry\n",
    "\n",
    "    daofind = DAOStarFinder(fwhm=3.0, threshold=10.*std)    # default threshold=5*std, fwhm=3\n",
    "    sources = daofind(data)    \n",
    "\n",
    "    #sources.pprint_all()\n",
    "    #print(sources['xcentroid','ycentroid','peak'])   \n",
    "\n",
    "    # Create apertures for x,y positions\n",
    "    positions = tuple(zip(sources['xcentroid'], sources['ycentroid']))\n",
    "    #print(positions)\n",
    "\n",
    "    #positions = (sources['xcentroid'], sources['ycentroid'])\n",
    "    apertures = CircularAperture(positions, r=ap_radius)\n",
    "    \n",
    "    # using wcs info from images, put coordinates into RA, Dec\n",
    "    ra, dec = image.meta.wcs(sources['xcentroid'], sources['ycentroid'])\n",
    "\n",
    "    # add RA, Dec to sources table\n",
    "\n",
    "    ra_col = Column(name='RA', data=ra)\n",
    "    dec_col = Column(name='Dec', data=dec)\n",
    "    sources.add_column(ra_col)\n",
    "    sources.add_column(dec_col)\n",
    "\n",
    "    # print RA, Dec for each x, y position found\n",
    "    #print(sources['xcentroid', 'ycentroid', 'RA', 'Dec'])  \n",
    "\n",
    "    sources_sub = sources['xcentroid', 'ycentroid', 'RA', 'Dec']\n",
    "    sources_sub.pprint_all()\n",
    "    print()\n",
    "    \n",
    "    # read in text file with RA and Dec input coordinates\n",
    "    RA_in, Dec_in = np.loadtxt( coords, dtype=str, unpack=True)\n",
    "\n",
    "    # put RA and Dec into floats\n",
    "    RA_sim = RA_in.astype(float)\n",
    "    Dec_sim = Dec_in.astype(float)\n",
    "    \n",
    "    # Put ra, dec coords into a table\n",
    "    cat1_sim = Table([RA_sim, Dec_sim], names=('ra', 'dec'))\n",
    "    cat2_calc = Table([ra, dec], names=('ra', 'dec'))\n",
    "    \n",
    "    # Get coordinates with SkyCoord for each catalog\n",
    "    \n",
    "    coord_cat1_sim = SkyCoord(ra=cat1_sim['ra'], dec=cat1_sim['dec'], unit=\"deg\")\n",
    "    coord_cat2_calc = SkyCoord(ra=cat2_calc['ra'], dec=cat2_calc['dec'], unit=\"deg\")\n",
    "    ind_cat2_cat1, dist_2d, _ = match_coordinates_sky(coord_cat1_sim, coord_cat2_calc)\n",
    "    \n",
    "    # Find where the catalogs match\n",
    "    \n",
    "    cat1_matched = cat1_sim[dist_2d.arcsec<0.05]\n",
    "    cat2_matched = cat2_calc[ind_cat2_cat1[dist_2d.arcsec<0.05]]\n",
    "    \n",
    "    #print(cat1_matched)\n",
    "    \n",
    "    # Get differences in RA, Dec\n",
    "    ra_diff = cat2_matched['ra'] - cat1_matched['ra']\n",
    "    dec_diff = cat2_matched['dec'] - cat1_matched['dec'] \n",
    "    \n",
    "    #print(ra_diff)\n",
    "    \n",
    "    # put differences in milliarcseconds\n",
    "    ra_diff = ra_diff * 3600000\n",
    "    dec_diff = dec_diff * 3600000\n",
    "    \n",
    "    \n",
    "    # Compare input RA, Dec to found RA, Dec\n",
    "    print('RA_Diff (mas)  Dec_diff (mas) pass/fail')\n",
    "    # Find if the differences are within the allowed 30 mas range\n",
    "    for i in np.arange(0,len(ra_diff)):\n",
    "        #if ra_diff[i] < 30 and dec_diff[i] < 30:\n",
    "        allRAdiff_i2d.append(ra_diff[i])\n",
    "        allDecdiff_i2d.append(dec_diff[i])\n",
    "        if abs(ra_diff[i]) < 30 and abs(dec_diff[i]) < 30: \n",
    "            test = 'pass' \n",
    "        else: \n",
    "            test = 'fail'\n",
    "        print('{:15.6f} {:15.6f} {}'.format(ra_diff[i], dec_diff[i], test))\n",
    " \n",
    "    \n",
    "    # Plot ra and dec differences\n",
    "    plt.title ('Differences in RA and Dec in milliarcseconds')\n",
    "    plt.ylabel('Delta RA')\n",
    "    plt.xlabel('Delta Dec')\n",
    "    plt.scatter(ra_diff,dec_diff)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot should show no differences greater than 30 milliarcseconds  \n",
    "\n",
    "    \n",
    "meanRAdiff_i2d, medianRAdiff_i2d, stdRAdiff_i2d = sigma_clipped_stats(allRAdiff_i2d, sigma=5.0, maxiters=5)  # default sigma=3\n",
    "meanDecdiff_i2d, medianDecdiff_i2d, stdDecdiff_i2d = sigma_clipped_stats(allDecdiff_i2d, sigma=5.0, maxiters=5)  # default sigma=3\n",
    "\n",
    "print('RA difference mean, median and std (units in mas)',meanRAdiff_i2d, medianRAdiff_i2d, stdRAdiff_i2d) \n",
    "print('Dec difference mean, median and std (units in mas)',meanDecdiff_i2d, medianDecdiff_i2d, stdDecdiff_i2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at positions of RA, Dec and get stats on differences for the combined image run with tweakreg on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = ImageModel('starfield_50star4ptdither_combined_i2d.fits')\n",
    "pixarea = im.meta.photometry.pixelarea_steradians\n",
    "print('Pixel area in steradians', pixarea)\n",
    "\n",
    "# pull out data portion of input file\n",
    "data = im.data\n",
    "\n",
    "# print stats on input image\n",
    "mean, median, std = sigma_clipped_stats(data, sigma=200.0, maxiters=5)  # default sigma=3\n",
    "print('Image mean, median and std',mean, median, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run DAOStarFinder to find sources in image\n",
    "\n",
    "ap_radius = 5.  # radius for aperture for centroiding and photometry\n",
    "\n",
    "daofind = DAOStarFinder(fwhm=3.0, threshold=10.*std)    # default threshold=5*std, fwhm=3\n",
    "sources = daofind(data)    \n",
    "\n",
    "# Create apertures for x,y positions\n",
    "positions = tuple(zip(sources['xcentroid'], sources['ycentroid']))\n",
    "#print(positions)\n",
    "\n",
    "#positions = (sources['xcentroid'], sources['ycentroid'])\n",
    "apertures = CircularAperture(positions, r=ap_radius)\n",
    "\n",
    "# using wcs info from images, put coordinates into RA, Dec\n",
    "ra, dec = im.meta.wcs(sources['xcentroid'], sources['ycentroid'])\n",
    "\n",
    "# add RA, Dec to sources table\n",
    "\n",
    "ra_col = Column(name='RA', data=ra)\n",
    "dec_col = Column(name='Dec', data=dec)\n",
    "sources.add_column(ra_col)\n",
    "sources.add_column(dec_col)\n",
    "\n",
    "# print RA, Dec for each x, y position found\n",
    "#print(sources['xcentroid', 'ycentroid', 'RA', 'Dec'])  \n",
    "\n",
    "sources_sub = sources['xcentroid', 'ycentroid', 'RA', 'Dec']\n",
    "sources_sub.pprint_all()\n",
    "print()\n",
    "\n",
    "# Compare input RA, Dec to found RA, Dec\n",
    "#print('       RA found       Dec found    RA_Diff (mas)  Dec_diff (mas) pass/fail')\n",
    "\n",
    "deltara_twon = []\n",
    "deltadec_twon = []\n",
    "\n",
    "# Put ra, dec coords into a table\n",
    "cat1_sim = Table([RA_sim, Dec_sim], names=('ra', 'dec'))\n",
    "cat2_calc = Table([ra, dec], names=('ra', 'dec'))\n",
    "    \n",
    "# Get coordinates with SkyCoord for each catalog\n",
    "    \n",
    "coord_cat1_sim = SkyCoord(ra=cat1_sim['ra'], dec=cat1_sim['dec'], unit=\"deg\")\n",
    "coord_cat2_calc = SkyCoord(ra=cat2_calc['ra'], dec=cat2_calc['dec'], unit=\"deg\")    \n",
    "ind_cat2_cat1, dist_2d, _ = match_coordinates_sky(coord_cat1_sim, coord_cat2_calc)\n",
    "    \n",
    "# Find where the catalogs match\n",
    "    \n",
    "cat1_matched = cat1_sim[dist_2d.arcsec<0.05]\n",
    "cat2_matched = cat2_calc[ind_cat2_cat1[dist_2d.arcsec<0.05]]\n",
    "    \n",
    "#print(cat1_matched)\n",
    "    \n",
    "# Get differences in RA, Dec\n",
    "ra_diff = cat2_matched['ra'] - cat1_matched['ra']\n",
    "dec_diff = cat2_matched['dec'] - cat1_matched['dec'] \n",
    "    \n",
    "#print(ra_diff)\n",
    "    \n",
    "# put differences in milliarcseconds\n",
    "ra_diff = ra_diff * 3600000\n",
    "dec_diff = dec_diff * 3600000\n",
    "    \n",
    "    \n",
    "# Compare input RA, Dec to found RA, Dec\n",
    "print('RA_Diff (mas)  Dec_diff (mas) pass/fail')\n",
    "# Find if the differences are within the allowed 30 mas range\n",
    "for i in np.arange(0,len(ra_diff)):\n",
    "    #if ra_diff[i] < 30 and dec_diff[i] < 30:\n",
    "    deltara_twon.append(ra_diff[i])\n",
    "    deltadec_twon.append(dec_diff[i])\n",
    "    if abs(ra_diff[i]) < 30 and abs(dec_diff[i]) < 30: \n",
    "        test = 'pass' \n",
    "    else: \n",
    "        test = 'fail'\n",
    "    print('{:15.6f} {:15.6f} {}'.format(ra_diff[i], dec_diff[i], test))\n",
    " \n",
    "    \n",
    "# Plot ra and dec differences\n",
    "plt.title ('Differences in RA and Dec in milliarcseconds')\n",
    "plt.ylabel('Delta RA')\n",
    "plt.xlabel('Delta Dec')\n",
    "plt.scatter(deltara_twon,deltadec_twon)\n",
    "plt.show()\n",
    "\n",
    "# Plot should show no differences greater than 30 milliarcseconds  \n",
    "     \n",
    "meanRAdiff_twon, medianRAdiff_twon, stdRAdiff_twon = sigma_clipped_stats(deltara_twon, sigma=5.0, maxiters=5)  # default sigma=3\n",
    "meanDecdiff_twon, medianDecdiff_twon, stdDecdiff_twon = sigma_clipped_stats(deltadec_twon, sigma=5.0, maxiters=5)  # default sigma=3\n",
    "\n",
    "print('RA difference mean, median and std (units in mas)',meanRAdiff_twon, medianRAdiff_twon, stdRAdiff_twon) \n",
    "print('Dec difference mean, median and std (units in mas)',meanDecdiff_twon, medianDecdiff_twon, stdDecdiff_twon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark sources on image frame to see if the correct sources were found\n",
    "norm = ImageNormalize(stretch=SqrtStretch())\n",
    "# keep image stretch in mind for plotting. sky subtracted range ~ (-15, 10), single sample ~ (0, 20)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(data, cmap='Greys', origin='lower', vmin=5,vmax=15)#, norm=norm)\n",
    "apertures.plot(color='red', lw=2.5) #, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run calwebb_image3 with tweakreg turned off\n",
    "\n",
    "Re-run the pipeline with tweakreg turned off to see if the differences found in the previous step are due to tweakreg alone, or differences in the distortion model that would show up in any run of the calwebb_image3 pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Calwebb_image3 on the association table with tweakreg off\n",
    "    \n",
    "# set any specific parameters\n",
    "# tweakreg parameters to allow data to run\n",
    "fwhm = 3.318 #3.27  # Gaussian kernel FWHM of objects expected, default=2.5\n",
    "minobj = 5  # minimum number of objects needed to match positions for a good fit, default=15\n",
    "snr = 10 # signal to noise threshold, default=5\n",
    "sigma = 3 # clipping limit, in sigma units, used when performing fit, default=3\n",
    "fit_geom ='rshift' # ftype of affine transformation to be considered when fitting catalogs, default='general'\n",
    "use2dhist = False  # boolean indicating whether to use 2D histogram to find initial offset, default=True\n",
    "   \n",
    "pipe3=Image3Pipeline()    \n",
    "#pipe3.tweakreg.kernel_fwhm = fwhm\n",
    "#pipe3.tweakreg.snr_threshold = snr\n",
    "#pipe3.tweakreg.minobj = minobj\n",
    "#pipe3.tweakreg.sigma = sigma\n",
    "#pipe3.tweakreg.fitgeometry = fit_geom\n",
    "#pipe3.tweakreg.use2dhist = use2dhist\n",
    "pipe3.tweakreg.skip = True        # test to see if this affects the final output\n",
    "pipe3.outlier_detection.skip = True # this is set in later step so mis-alignments aren't 'hidden'\n",
    "pipe3.source_catalog.save_results = True\n",
    "pipe3.save_results = True\n",
    "#pipe3.output_dir = datadir\n",
    "\n",
    "# run Image3\n",
    "\n",
    "#im = pipe3.run(rtdata.input)\n",
    "image = pipe3.run('starfield_50star4ptdither_asnfile.json')\n",
    "print('Image 3 pipeline finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = ImageModel('starfield_50star4ptdither_combined_i2d.fits')\n",
    "pixarea = im.meta.photometry.pixelarea_steradians\n",
    "print('Pixel area in steradians', pixarea)\n",
    "\n",
    "# pull out data portion of input file\n",
    "data = im.data\n",
    "\n",
    "# print stats on input image\n",
    "mean, median, std = sigma_clipped_stats(data, sigma=200.0, maxiters=5)  # default sigma=3\n",
    "print('Image mean, median and std',mean, median, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DAOStarFinder to find sources in image\n",
    "\n",
    "ap_radius = 5.  # radius for aperture for centroiding and photometry\n",
    "\n",
    "daofind = DAOStarFinder(fwhm=3.0, threshold=10.*std)    # default threshold=5*std, fwhm=3\n",
    "sources = daofind(data)    \n",
    "\n",
    "#sources.pprint_all()\n",
    "#print(sources['xcentroid','ycentroid','peak'])   \n",
    "\n",
    "# Create apertures for x,y positions\n",
    "positions = tuple(zip(sources['xcentroid'], sources['ycentroid']))\n",
    "#print(positions)\n",
    "\n",
    "#positions = (sources['xcentroid'], sources['ycentroid'])\n",
    "apertures = CircularAperture(positions, r=ap_radius)\n",
    "\n",
    "\n",
    "# using wcs info from images, put coordinates into RA, Dec\n",
    "ra, dec = im.meta.wcs(sources['xcentroid'], sources['ycentroid'])\n",
    "\n",
    "# add RA, Dec to sources table\n",
    "\n",
    "ra_col = Column(name='RA', data=ra)\n",
    "dec_col = Column(name='Dec', data=dec)\n",
    "sources.add_column(ra_col)\n",
    "sources.add_column(dec_col)\n",
    "\n",
    "# print RA, Dec for each x, y position found\n",
    "#print(sources['xcentroid', 'ycentroid', 'RA', 'Dec'])  \n",
    "\n",
    "sources_sub = sources['xcentroid', 'ycentroid', 'RA', 'Dec']\n",
    "sources_sub.pprint_all()\n",
    "print()\n",
    "\n",
    "# Compare input RA, Dec to found RA, Dec\n",
    "#print('       RA found       Dec found    RA_Diff (mas)  Dec_diff (mas) pass/fail')\n",
    "\n",
    "deltara_twoff = []\n",
    "deltadec_twoff = []\n",
    "\n",
    "# Put ra, dec coords into a table\n",
    "cat1_sim = Table([RA_sim, Dec_sim], names=('ra', 'dec'))\n",
    "cat2_calc = Table([ra, dec], names=('ra', 'dec'))\n",
    "    \n",
    "# Get coordinates with SkyCoord for each catalog\n",
    "    \n",
    "coord_cat1_sim = SkyCoord(ra=cat1_sim['ra'], dec=cat1_sim['dec'], unit=\"deg\")\n",
    "coord_cat2_calc = SkyCoord(ra=cat2_calc['ra'], dec=cat2_calc['dec'], unit=\"deg\")    \n",
    "ind_cat2_cat1, dist_2d, _ = match_coordinates_sky(coord_cat1_sim, coord_cat2_calc)\n",
    "    \n",
    "# Find where the catalogs match\n",
    "    \n",
    "cat1_matched = cat1_sim[dist_2d.arcsec<0.05]\n",
    "cat2_matched = cat2_calc[ind_cat2_cat1[dist_2d.arcsec<0.05]]\n",
    "    \n",
    "#print(cat1_matched)\n",
    "    \n",
    "# Get differences in RA, Dec\n",
    "ra_diff = cat2_matched['ra'] - cat1_matched['ra']\n",
    "dec_diff = cat2_matched['dec'] - cat1_matched['dec'] \n",
    "    \n",
    "#print(ra_diff)\n",
    "    \n",
    "# put differences in milliarcseconds\n",
    "ra_diff = ra_diff * 3600000\n",
    "dec_diff = dec_diff * 3600000\n",
    "    \n",
    "    \n",
    "# Compare input RA, Dec to found RA, Dec\n",
    "print('RA_Diff (mas)  Dec_diff (mas) pass/fail')\n",
    "# Find if the differences are within the allowed 30 mas range\n",
    "for i in np.arange(0,len(ra_diff)):\n",
    "    #if ra_diff[i] < 30 and dec_diff[i] < 30:\n",
    "    deltara_twoff.append(ra_diff[i])\n",
    "    deltadec_twoff.append(dec_diff[i])\n",
    "    if abs(ra_diff[i]) < 30 and abs(dec_diff[i]) < 30: \n",
    "        test = 'pass' \n",
    "    else: \n",
    "        test = 'fail'\n",
    "    print('{:15.6f} {:15.6f} {}'.format(ra_diff[i], dec_diff[i], test))\n",
    " \n",
    "    \n",
    "# Plot ra and dec differences\n",
    "plt.title ('Differences in RA and Dec in milliarcseconds')\n",
    "plt.ylabel('Delta RA')\n",
    "plt.xlabel('Delta Dec')\n",
    "plt.scatter(deltara_twoff,deltadec_twoff)\n",
    "plt.show()\n",
    "\n",
    "# Plot should show no differences greater than 30 milliarcseconds      \n",
    "    \n",
    "meanRAdiff_twoff, medianRAdiff_twoff, stdRAdiff_twoff = sigma_clipped_stats(deltara_twoff, sigma=5.0, maxiters=5)  # default sigma=3\n",
    "meanDecdiff_twoff, medianDecdiff_twoff, stdDecdiff_twoff = sigma_clipped_stats(deltadec_twoff, sigma=5.0, maxiters=5)  # default sigma=3\n",
    "\n",
    "print('RA difference mean, median and std (units in mas)',meanRAdiff_twoff, medianRAdiff_twoff, stdRAdiff_twoff) \n",
    "print('Dec difference mean, median and std (units in mas)',meanDecdiff_twoff, medianDecdiff_twoff, stdDecdiff_twoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark sources on image frame to see if the correct sources were found\n",
    "norm = ImageNormalize(stretch=SqrtStretch())\n",
    "# keep image stretch in mind for plotting. sky subtracted range ~ (-15, 10), single sample ~ (0, 20)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(data, cmap='Greys', origin='lower', vmin=5,vmax=15)#, norm=norm)\n",
    "apertures.plot(color='red', lw=2.5) #, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare stats across tests:\n",
    "\n",
    "print('All units are milliarcseconds for statistics')\n",
    "print('Statistics on differences between RA and Dec in individual calibrated files')\n",
    "print('RA difference mean, median and std',meanRAdiff_cal, medianRAdiff_cal, stdRAdiff_cal) \n",
    "print('Dec difference mean, median and std',meanDecdiff_cal, medianDecdiff_cal, stdDecdiff_cal)\n",
    "print()\n",
    "print('Statistics on differences between RA and Dec in individual i2d files when run with tweakreg on')\n",
    "print('RA difference mean, median and std',meanRAdiff_i2d, medianRAdiff_i2d, stdRAdiff_i2d) \n",
    "print('Dec difference mean, median and std',meanDecdiff_i2d, medianDecdiff_i2d, stdDecdiff_i2d)\n",
    "print()\n",
    "print('Statistics on differences between RA and Dec in combined i2d file when run with tweakreg on')\n",
    "print('RA difference mean, median and std',meanRAdiff_twon, medianRAdiff_twon, stdRAdiff_twon) \n",
    "print('Dec difference mean, median and std',meanDecdiff_twon, medianDecdiff_twon, stdDecdiff_twon)\n",
    "print()\n",
    "print('Statistics on differences between RA and Dec in combined i2d file when run with tweakreg off')\n",
    "print('RA difference mean, median and std',meanRAdiff_twoff, medianRAdiff_twoff, stdRAdiff_twoff) \n",
    "print('Dec difference mean, median and std',meanDecdiff_twoff, medianDecdiff_twoff, stdDecdiff_twoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test # 2: See what happens with tweakreg when there are shifts between images not tracked in the wcs.\n",
    "\n",
    "This test uses MIRISim data using only the simulated dithers, and one shifted image. Two exposures each of four different dithers. \n",
    "\n",
    "First look at the cal images out of calwebb_image2. \n",
    "* Apply specified shift (~0.5 arcseconds) to x and y positions of one image\n",
    "* Use DAOStarFinder to get the x,y positions of the stars in each image\n",
    "* Use wcs info from image to convert x,y positions to RA, Dec\n",
    "* Compare the RA, Dec calculated values to the RA, Dec positions put into the simulated images\n",
    "* Get statistics on the differences of the calculated and input positions in units of mas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply shifts to files in input list\n",
    "\n",
    "# Read in a single rate.fits file, modify header values RA_REF and DEC_REF by adding in a shift of less than one \n",
    "# arcsecond, which is the default search radius for tweakreg\n",
    "# 0.72 arcseconds ~ 0.0002 degrees\n",
    "# 0.5 arcseconds ~ 0.00014 degrees\n",
    "\n",
    "origfile = 'starfield_50star4ptdither_seq2_MIRIMAGE_F1130Wexp2_rate.fits'\n",
    "\n",
    "model = ImageModel(origfile)\n",
    "\n",
    "# modify header vaules\n",
    "\n",
    "model.meta.wcsinfo.ra_ref = model.meta.wcsinfo.ra_ref + 0.00014\n",
    "model.meta.wcsinfo.dec_ref = model.meta.wcsinfo.dec_ref + 0.00014\n",
    "\n",
    "# Run file through calwebb_image2 to get cal.fits version and then retest steps in Test # 1.\n",
    "\n",
    "# create an object for the pipeline    \n",
    "pipe2 = Image2Pipeline()\n",
    "pipe2.save_results = True\n",
    "#pipe2.output_file = rampfile+'_cal.fits'\n",
    "#pipe2.output_dir = datadir\n",
    "pipe2.run(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find stars and get RA, Dec from *_cal.fits files\n",
    "\n",
    "# Run DAOStarFinder to find sources in image\n",
    "allRAdiff_cal = []\n",
    "allDecdiff_cal = []\n",
    "\n",
    "for calimage in imagelist:\n",
    "    image = ImageModel(calimage)\n",
    "    \n",
    "    # pull out data portion of input file\n",
    "    data = image.data\n",
    "    \n",
    "    # print stats on input image\n",
    "    print(calimage)\n",
    "    mean, median, std = sigma_clipped_stats(data, sigma=200.0, maxiters=5)  # default sigma=3\n",
    "    print('Image mean, median and std',mean, median, std)\n",
    "\n",
    "    ap_radius = 5.  # radius for aperture for centroiding and photometry\n",
    "\n",
    "    daofind = DAOStarFinder(fwhm=3.0, threshold=10.*std)    # default threshold=5*std, fwhm=3\n",
    "    sources = daofind(data)      \n",
    "\n",
    "    # Create apertures for x,y positions\n",
    "    positions = tuple(zip(sources['xcentroid'], sources['ycentroid']))\n",
    "    #print(positions)\n",
    "\n",
    "    #positions = (sources['xcentroid'], sources['ycentroid'])\n",
    "    apertures = CircularAperture(positions, r=ap_radius)\n",
    "    \n",
    "    # using wcs info from images, put coordinates into RA, Dec\n",
    "    ra, dec = image.meta.wcs(sources['xcentroid'], sources['ycentroid'])\n",
    "\n",
    "    # add RA, Dec to sources table\n",
    "\n",
    "    ra_col = Column(name='RA', data=ra)\n",
    "    dec_col = Column(name='Dec', data=dec)\n",
    "    sources.add_column(ra_col)\n",
    "    sources.add_column(dec_col)\n",
    "\n",
    "    # print RA, Dec for each x, y position found\n",
    "    #print(sources['xcentroid', 'ycentroid', 'RA', 'Dec'])  \n",
    "\n",
    "    sources_sub = sources['xcentroid', 'ycentroid', 'RA', 'Dec']\n",
    "    sources_sub.pprint_all()\n",
    "    print()\n",
    "    \n",
    "    # read in text file with RA and Dec input coordinates\n",
    "    RA_in, Dec_in = np.loadtxt(coords, dtype=str, unpack=True)\n",
    "\n",
    "    # put RA and Dec into floats\n",
    "    RA_sim = RA_in.astype(float)\n",
    "    Dec_sim = Dec_in.astype(float)\n",
    "    \n",
    "    # Put ra, dec coords into a table\n",
    "    cat1_sim = Table([RA_sim, Dec_sim], names=('ra', 'dec'))\n",
    "    cat2_calc = Table([ra, dec], names=('ra', 'dec'))\n",
    "    \n",
    "\n",
    "    # Get coordinates with SkyCoord for each catalog\n",
    "    \n",
    "    coord_cat1_sim = SkyCoord(ra=cat1_sim['ra'], dec=cat1_sim['dec'], unit=\"deg\")\n",
    "    coord_cat2_calc = SkyCoord(ra=cat2_calc['ra'], dec=cat2_calc['dec'], unit=\"deg\")\n",
    "    ind_cat2_cat1, dist_2d, _ = match_coordinates_sky(coord_cat1_sim, coord_cat2_calc)\n",
    "    \n",
    "    # Find where the catalogs match\n",
    "    \n",
    "    cat1_matched = cat1_sim[dist_2d.arcsec<0.05]\n",
    "    cat2_matched = cat2_calc[ind_cat2_cat1[dist_2d.arcsec<0.05]]\n",
    "    \n",
    "    #print(cat1_matched)\n",
    "    \n",
    "    # Get differences in RA, Dec\n",
    "    ra_diff = cat2_matched['ra'] - cat1_matched['ra']\n",
    "    dec_diff = cat2_matched['dec'] - cat1_matched['dec'] \n",
    "    \n",
    "    #print(ra_diff)\n",
    "    \n",
    "    # put differences in milliarcseconds\n",
    "    ra_diff = ra_diff * 3600000\n",
    "    dec_diff = dec_diff * 3600000\n",
    "    \n",
    "    \n",
    "    # Compare input RA, Dec to found RA, Dec\n",
    "    print('RA_Diff (mas)  Dec_diff (mas) pass/fail')\n",
    "    # Find if the differences are within the allowed 30 mas range\n",
    "    for i in np.arange(0,len(ra_diff)):\n",
    "        #if ra_diff[i] < 30 and dec_diff[i] < 30:\n",
    "        allRAdiff_cal.append(ra_diff[i])\n",
    "        allDecdiff_cal.append(dec_diff[i])\n",
    "        if abs(ra_diff[i]) < 30 and abs(dec_diff[i]) < 30: \n",
    "            test = 'pass' \n",
    "        else: \n",
    "            test = 'fail'\n",
    "        print('{:15.6f} {:15.6f} {}'.format(ra_diff[i], dec_diff[i], test))\n",
    " \n",
    "    \n",
    "    # Plot ra and dec differences\n",
    "    plt.title ('Differences in RA and Dec in milliarcseconds')\n",
    "    plt.ylabel('Delta RA')\n",
    "    plt.xlabel('Delta Dec')\n",
    "    plt.scatter(ra_diff,dec_diff)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot should show no differences greater than 30 milliarcseconds  \n",
    "    \n",
    "meanRAdiff_cal, medianRAdiff_cal, stdRAdiff_cal = sigma_clipped_stats(allRAdiff_cal, sigma=5.0, maxiters=5)  # default sigma=3\n",
    "meanDecdiff_cal, medianDecdiff_cal, stdDecdiff_cal = sigma_clipped_stats(allDecdiff_cal, sigma=5.0, maxiters=5)  # default sigma=3\n",
    "\n",
    "print('RA difference mean, median and std (units in mas)',meanRAdiff_cal, medianRAdiff_cal, stdRAdiff_cal) \n",
    "print('Dec difference mean, median and std (units in mas)',meanDecdiff_cal, medianDecdiff_cal, stdDecdiff_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the images through calwebb_image3 with tweakreg on\n",
    "\n",
    "Alter any parameters needed to get better results from tweakreg. Look at individual i2d images afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Calwebb_image3 on the association table with tweakreg on\n",
    "    \n",
    "# set any specific parameters\n",
    "# tweakreg parameters to allow data to run\n",
    "fwhm = 3.318 #3.27  # Gaussian kernel FWHM of objects expected, default=2.5\n",
    "minobj = 5  # minimum number of objects needed to match positions for a good fit, default=15\n",
    "snr = 40 # signal to noise threshold, default=5\n",
    "sigma = 3 # clipping limit, in sigma units, used when performing fit, default=3\n",
    "fit_geom ='rshift' # ftype of affine transformation to be considered when fitting catalogs, default='general'\n",
    "use2dhist = False  # boolean indicating whether to use 2D histogram to find initial offset, default=True\n",
    "search_radius = 1.0 # radius in arcseconds to search for a match\n",
    "tol = 1.0  # Matching tolerance for xyxymatch in arcsec. (Default=1.0)\n",
    "use2dhist = True  # boolean indicating whether to use 2D histogram to find initial offset, default=True\n",
    "   \n",
    "pipe3=Image3Pipeline()    \n",
    "pipe3.tweakreg.kernel_fwhm = fwhm\n",
    "pipe3.tweakreg.snr_threshold = snr\n",
    "pipe3.tweakreg.minobj = minobj\n",
    "pipe3.tweakreg.sigma = sigma\n",
    "pipe3.tweakreg.fitgeometry = fit_geom\n",
    "pipe3.tweakreg.use2dhist = use2dhist\n",
    "pipe3.tweakreg.save_catalogs = True\n",
    "#pipe3.tweakreg.skip = True        # test to see if this affects the final output\n",
    "pipe3.outlier_detection.skip = True\n",
    "pipe3.source_catalog.save_results = True\n",
    "pipe3.save_results = True\n",
    "#pipe3.output_dir = datadir\n",
    "\n",
    "# run Image3\n",
    "\n",
    "#im = pipe3.run(rtdata.input)\n",
    "image = pipe3.run('starfield_50star4ptdither_asnfile.json')\n",
    "print('Image 3 pipeline finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go through list of individual images and see which sources were found for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of catalogs\n",
    "\n",
    "cataloglist = [ele.replace('cal.fits', 'cal_cat.ecsv') for ele in imagelist]\n",
    "print(imagelist)\n",
    "print()\n",
    "print(cataloglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each image and overplot the sources found in the individual catalogs\n",
    "\n",
    "index=0\n",
    "for cal_image in imagelist:\n",
    "    indimage = ImageModel(cal_image)\n",
    "    ind_data = indimage.data\n",
    "    \n",
    "    indcat = cataloglist[index]\n",
    "    catdata = table.Table.read(indcat, format='ascii', comment='#')\n",
    "    print(cal_image)\n",
    "    print(indcat)\n",
    "    print(len(catdata['xcentroid']), 'sources found')\n",
    "    \n",
    "    # mark sources on image frame to see if the correct sources were found\n",
    "    norm = ImageNormalize(stretch=SqrtStretch())\n",
    "    # keep image stretch in mind for plotting. sky subtracted range ~ (-15, 10), single sample ~ (0, 20)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(ind_data, cmap='Greys', origin='lower', vmin=0,vmax=50)#, norm=norm)\n",
    "    plt.scatter(catdata['xcentroid'], catdata['ycentroid'],lw=1, s=20,color='red')\n",
    "    plt.show()\n",
    "    index = index+1\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at positions of RA, Dec and get stats on differences for the combined image run with tweakreg on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = ImageModel('starfield_50star4ptdither_combined_i2d.fits')\n",
    "pixarea = im.meta.photometry.pixelarea_steradians\n",
    "print('Pixel area in steradians', pixarea)\n",
    "\n",
    "# pull out data portion of input file\n",
    "data = im.data\n",
    "\n",
    "# print stats on input image\n",
    "mean, median, std = sigma_clipped_stats(data, sigma=200.0, maxiters=5)  # default sigma=3\n",
    "print('Image mean, median and std',mean, median, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DAOStarFinder to find sources in image\n",
    "\n",
    "ap_radius = 5.  # radius for aperture for centroiding and photometry\n",
    "\n",
    "daofind = DAOStarFinder(fwhm=3.0, threshold=10.*std)    # default threshold=5*std, fwhm=3\n",
    "sources = daofind(data)    \n",
    "\n",
    "# Create apertures for x,y positions\n",
    "positions = tuple(zip(sources['xcentroid'], sources['ycentroid']))\n",
    "#print(positions)\n",
    "\n",
    "#positions = (sources['xcentroid'], sources['ycentroid'])\n",
    "apertures = CircularAperture(positions, r=ap_radius)\n",
    "\n",
    "# using wcs info from images, put coordinates into RA, Dec\n",
    "ra, dec = im.meta.wcs(sources['xcentroid'], sources['ycentroid'])\n",
    "\n",
    "print('Number of sources found with DAOStarFinder: ',np.size(ra))\n",
    "\n",
    "# add RA, Dec to sources table\n",
    "\n",
    "ra_col = Column(name='RA', data=ra)\n",
    "dec_col = Column(name='Dec', data=dec)\n",
    "sources.add_column(ra_col)\n",
    "sources.add_column(dec_col)\n",
    "\n",
    "# print RA, Dec for each x, y position found\n",
    "#print(sources['xcentroid', 'ycentroid', 'RA', 'Dec'])  \n",
    "\n",
    "sources_sub = sources['xcentroid', 'ycentroid', 'RA', 'Dec']\n",
    "sources_sub.pprint_all()\n",
    "print()\n",
    "\n",
    "# Put ra, dec coords into a table\n",
    "cat1_sim = Table([RA_sim, Dec_sim], names=('ra', 'dec'))\n",
    "cat2_calc = Table([ra, dec], names=('ra', 'dec'))\n",
    "    \n",
    "# Get coordinates with SkyCoord for each catalog\n",
    "    \n",
    "coord_cat1_sim = SkyCoord(ra=cat1_sim['ra'], dec=cat1_sim['dec'], unit=\"deg\")\n",
    "coord_cat2_calc = SkyCoord(ra=cat2_calc['ra'], dec=cat2_calc['dec'], unit=\"deg\")    \n",
    "ind_cat2_cat1, dist_2d, _ = match_coordinates_sky(coord_cat1_sim, coord_cat2_calc)\n",
    "    \n",
    "# Find where the catalogs match\n",
    "    \n",
    "cat1_matched = cat1_sim[dist_2d.arcsec<0.05]\n",
    "cat2_matched = cat2_calc[ind_cat2_cat1[dist_2d.arcsec<0.05]]\n",
    "    \n",
    "#print(cat1_matched)\n",
    "    \n",
    "# Get differences in RA, Dec\n",
    "ra_diff = cat2_matched['ra'] - cat1_matched['ra']\n",
    "dec_diff = cat2_matched['dec'] - cat1_matched['dec'] \n",
    "    \n",
    "#print(ra_diff)\n",
    "    \n",
    "# put differences in milliarcseconds\n",
    "ra_diff = ra_diff * 3600000\n",
    "dec_diff = dec_diff * 3600000\n",
    "\n",
    "deltara_twon = []\n",
    "deltadec_twon = []\n",
    "    \n",
    "# Compare input RA, Dec to found RA, Dec\n",
    "print('RA_Diff (mas)  Dec_diff (mas) pass/fail')\n",
    "# Find if the differences are within the allowed 30 mas range\n",
    "for i in np.arange(0,len(ra_diff)):\n",
    "    #if ra_diff[i] < 30 and dec_diff[i] < 30:\n",
    "    deltara_twon.append(ra_diff[i])\n",
    "    deltadec_twon.append(dec_diff[i])\n",
    "    if abs(ra_diff[i]) < 30 and abs(dec_diff[i]) < 30: \n",
    "        test = 'pass' \n",
    "    else: \n",
    "        test = 'fail'\n",
    "    print('{:15.6f} {:15.6f} {}'.format(ra_diff[i], dec_diff[i], test))\n",
    " \n",
    "    \n",
    "# Plot ra and dec differences\n",
    "plt.title ('Differences in RA and Dec in milliarcseconds')\n",
    "plt.ylabel('Delta RA')\n",
    "plt.xlabel('Delta Dec')\n",
    "plt.scatter(deltara_twon,deltadec_twon)\n",
    "plt.show()\n",
    "\n",
    "# Plot should show no differences greater than 30 milliarcseconds  \n",
    "\n",
    "print()\n",
    "print('Number of sources matched: ', np.size(deltara_twon))\n",
    "# Plot ra and dec differences\n",
    "plt.title ('Differences in RA and Dec in milliarcseconds')\n",
    "plt.ylabel('Delta RA')\n",
    "plt.xlabel('Delta Dec')\n",
    "plt.scatter(deltadec_twon,deltara_twon)\n",
    "plt.show()\n",
    "\n",
    "# Plot should show no differences greater than 30 milliarcseconds      \n",
    "\n",
    "    \n",
    "meanRAdiff_twon, medianRAdiff_twon, stdRAdiff_twon = sigma_clipped_stats(deltara_twon, sigma=5.0, maxiters=5)  # default sigma=3\n",
    "meanDecdiff_twon, medianDecdiff_twon, stdDecdiff_twon = sigma_clipped_stats(deltadec_twon, sigma=5.0, maxiters=5)  # default sigma=3\n",
    "\n",
    "print('RA difference mean, median and std (units in mas)',meanRAdiff_twon, medianRAdiff_twon, stdRAdiff_twon) \n",
    "print('Dec difference mean, median and std (units in mas)',meanDecdiff_twon, medianDecdiff_twon, stdDecdiff_twon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark sources on image frame to see if the correct sources were found\n",
    "norm = ImageNormalize(stretch=SqrtStretch())\n",
    "# keep image stretch in mind for plotting. sky subtracted range ~ (-15, 10), single sample ~ (0, 20)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(data, cmap='Greys', origin='lower', vmin=5,vmax=15)#, norm=norm)\n",
    "apertures.plot(color='red', lw=2.5) #, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a closer look at a portion of the image to get a closer look at the psf\n",
    "\n",
    "# mark sources on image frame to see if the correct sources were found\n",
    "norm = ImageNormalize(stretch=SqrtStretch())\n",
    "# keep image stretch in mind for plotting. sky subtracted range ~ (-15, 10), single sample ~ (0, 20)\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "plt.imshow(data[350:450, 700:820], cmap='Greys', origin='lower', vmin=0,vmax=200)#, norm=norm)\n",
    "#apertures.plot(color='red', lw=2.5) #, alpha=0.5)\n",
    "#plt.scatter(sources['xcentroid']-700, sources['ycentroid']-350, color='red')\n",
    "#plt.ylim(350,450)\n",
    "#plt.xlim(700,820)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test again with tweakreg off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Calwebb_image3 on the association table with tweakreg on\n",
    "    \n",
    "# set any specific parameters\n",
    "# tweakreg parameters to allow data to run\n",
    "fwhm = 3.318 #3.27  # Gaussian kernel FWHM of objects expected, default=2.5\n",
    "minobj = 5  # minimum number of objects needed to match positions for a good fit, default=15\n",
    "snr = 40 # signal to noise threshold, default=5\n",
    "sigma = 3 # clipping limit, in sigma units, used when performing fit, default=3\n",
    "fit_geom ='rshift' # ftype of affine transformation to be considered when fitting catalogs, default='general'\n",
    "use2dhist = False  # boolean indicating whether to use 2D histogram to find initial offset, default=True\n",
    "   \n",
    "#pipe3=Image3Pipeline()    \n",
    "#pipe3.tweakreg.kernel_fwhm = fwhm\n",
    "#pipe3.tweakreg.snr_threshold = snr\n",
    "#pipe3.tweakreg.minobj = minobj\n",
    "#pipe3.tweakreg.sigma = sigma\n",
    "#pipe3.tweakreg.fitgeometry = fit_geom\n",
    "#pipe3.tweakreg.use2dhist = use2dhist\n",
    "pipe3.tweakreg.skip = True        # test to see if this affects the final output\n",
    "pipe3.outlier_detection.skip = True\n",
    "pipe3.source_catalog.save_results = True\n",
    "pipe3.save_results = True\n",
    "#pipe3.output_dir = datadir\n",
    "\n",
    "# run Image3\n",
    "\n",
    "#im = pipe3.run(rtdata.input)\n",
    "image = pipe3.run('starfield_50star4ptdither_asnfile.json')\n",
    "print('Image 3 pipeline finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = ImageModel('starfield_50star4ptdither_combined_i2d.fits')\n",
    "pixarea = im.meta.photometry.pixelarea_steradians\n",
    "print('Pixel area in steradians', pixarea)\n",
    "\n",
    "# pull out data portion of input file\n",
    "data = im.data\n",
    "\n",
    "# print stats on input image\n",
    "mean, median, std = sigma_clipped_stats(data, sigma=200.0, maxiters=5)  # default sigma=3\n",
    "print('Image mean, median and std',mean, median, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DAOStarFinder to find sources in image\n",
    "\n",
    "ap_radius = 5.  # radius for aperture for centroiding and photometry\n",
    "\n",
    "daofind = DAOStarFinder(fwhm=3.0, threshold=10.*std)    # default threshold=5*std, fwhm=3\n",
    "sources = daofind(data)    \n",
    "\n",
    "#sources.pprint_all()\n",
    "#print(sources['xcentroid','ycentroid','peak'])   \n",
    "\n",
    "# Create apertures for x,y positions\n",
    "positions = tuple(zip(sources['xcentroid'], sources['ycentroid']))\n",
    "#print(positions)\n",
    "\n",
    "#positions = (sources['xcentroid'], sources['ycentroid'])\n",
    "apertures = CircularAperture(positions, r=ap_radius)\n",
    "\n",
    "\n",
    "# using wcs info from images, put coordinates into RA, Dec\n",
    "ra, dec = im.meta.wcs(sources['xcentroid'], sources['ycentroid'])\n",
    "\n",
    "print('Number of sources found with DAOStarFinder: ',np.size(ra))\n",
    "# add RA, Dec to sources table\n",
    "\n",
    "ra_col = Column(name='RA', data=ra)\n",
    "dec_col = Column(name='Dec', data=dec)\n",
    "sources.add_column(ra_col)\n",
    "sources.add_column(dec_col)\n",
    "\n",
    "# print RA, Dec for each x, y position found\n",
    "#print(sources['xcentroid', 'ycentroid', 'RA', 'Dec'])  \n",
    "\n",
    "sources_sub = sources['xcentroid', 'ycentroid', 'RA', 'Dec']\n",
    "sources_sub.pprint_all()\n",
    "print()\n",
    "\n",
    "# Compare input RA, Dec to found RA, Dec\n",
    "#print('       RA found       Dec found    RA_Diff (mas)  Dec_diff (mas) pass/fail')\n",
    "\n",
    "deltara_twoff = []\n",
    "deltadec_twoff = []\n",
    "\n",
    "# Put ra, dec coords into a table\n",
    "cat1_sim = Table([RA_sim, Dec_sim], names=('ra', 'dec'))\n",
    "cat2_calc = Table([ra, dec], names=('ra', 'dec'))\n",
    "    \n",
    "# Get coordinates with SkyCoord for each catalog\n",
    "    \n",
    "coord_cat1_sim = SkyCoord(ra=cat1_sim['ra'], dec=cat1_sim['dec'], unit=\"deg\")\n",
    "coord_cat2_calc = SkyCoord(ra=cat2_calc['ra'], dec=cat2_calc['dec'], unit=\"deg\")    \n",
    "ind_cat2_cat1, dist_2d, _ = match_coordinates_sky(coord_cat1_sim, coord_cat2_calc)\n",
    "    \n",
    "# Find where the catalogs match\n",
    "    \n",
    "cat1_matched = cat1_sim[dist_2d.arcsec<0.05]\n",
    "cat2_matched = cat2_calc[ind_cat2_cat1[dist_2d.arcsec<0.05]]\n",
    "    \n",
    "#print(cat1_matched)\n",
    "    \n",
    "# Get differences in RA, Dec\n",
    "ra_diff = cat2_matched['ra'] - cat1_matched['ra']\n",
    "dec_diff = cat2_matched['dec'] - cat1_matched['dec'] \n",
    "    \n",
    "#print(ra_diff)\n",
    "    \n",
    "# put differences in milliarcseconds\n",
    "ra_diff = ra_diff * 3600000\n",
    "dec_diff = dec_diff * 3600000\n",
    "\n",
    "    \n",
    "# Compare input RA, Dec to found RA, Dec\n",
    "print('RA_Diff (mas)  Dec_diff (mas) pass/fail')\n",
    "# Find if the differences are within the allowed 30 mas range\n",
    "for i in np.arange(0,len(ra_diff)):\n",
    "    #if ra_diff[i] < 30 and dec_diff[i] < 30:\n",
    "    deltara_twoff.append(ra_diff[i])\n",
    "    deltadec_twoff.append(dec_diff[i])\n",
    "    if abs(ra_diff[i]) < 30 and abs(dec_diff[i]) < 30: \n",
    "        test = 'pass' \n",
    "    else: \n",
    "        test = 'fail'\n",
    "    print('{:15.6f} {:15.6f} {}'.format(ra_diff[i], dec_diff[i], test))\n",
    " \n",
    "    \n",
    "# Plot ra and dec differences\n",
    "plt.title ('Differences in RA and Dec in milliarcseconds')\n",
    "plt.ylabel('Delta RA')\n",
    "plt.xlabel('Delta Dec')\n",
    "plt.scatter(deltara_twoff,deltadec_twoff)\n",
    "plt.show()\n",
    "\n",
    "# Plot should show no differences greater than 30 milliarcseconds \n",
    "\n",
    "print()\n",
    "    \n",
    "meanRAdiff_twoff, medianRAdiff_twoff, stdRAdiff_twoff = sigma_clipped_stats(deltara_twoff, sigma=5.0, maxiters=5)  # default sigma=3\n",
    "meanDecdiff_twoff, medianDecdiff_twoff, stdDecdiff_twoff = sigma_clipped_stats(deltadec_twoff, sigma=5.0, maxiters=5)  # default sigma=3\n",
    "\n",
    "print('RA difference mean, median and std (units in mas)',meanRAdiff_twoff, medianRAdiff_twoff, stdRAdiff_twoff) \n",
    "print('Dec difference mean, median and std (units in mas)',meanDecdiff_twoff, medianDecdiff_twoff, stdDecdiff_twoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark sources on image frame to see if the correct sources were found\n",
    "norm = ImageNormalize(stretch=SqrtStretch())\n",
    "# keep image stretch in mind for plotting. sky subtracted range ~ (-15, 10), single sample ~ (0, 20)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(data, cmap='Greys', origin='lower', vmin=5,vmax=15)#, norm=norm)\n",
    "apertures.plot(color='red', lw=2.5) #, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a closer look at a portion of the image to get a closer look at the psf\n",
    "\n",
    "# mark sources on image frame to see if the correct sources were found\n",
    "norm = ImageNormalize(stretch=SqrtStretch())\n",
    "# keep image stretch in mind for plotting. sky subtracted range ~ (-15, 10), single sample ~ (0, 20)\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "plt.imshow(data[350:450, 700:820], cmap='Greys', origin='lower', vmin=0,vmax=200)#, norm=norm)\n",
    "\n",
    "#plt.scatter(sources['xcentroid']-700, sources['ycentroid']-350, color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare stats across tests:\n",
    "print('All units are milliarcseconds for statistics')\n",
    "print('Statistics on differences between RA and Dec in individual calibrated files')\n",
    "print('RA difference mean, median and std',meanRAdiff_cal, medianRAdiff_cal, stdRAdiff_cal) \n",
    "print('Dec difference mean, median and std',meanDecdiff_cal, medianDecdiff_cal, stdDecdiff_cal)\n",
    "print()\n",
    "#print('Statistics on differences between RA and Dec in individual i2d files when run with tweakreg on')\n",
    "#print('RA difference mean, median and std',meanRAdiff_i2d, medianRAdiff_i2d, stdRAdiff_i2d) \n",
    "#print('Dec difference mean, median and std',meanDecdiff_i2d, medianDecdiff_i2d, stdDecdiff_i2d)\n",
    "#print()\n",
    "print('Statistics on differences between RA and Dec in combined i2d file when run with tweakreg on')\n",
    "print('RA difference mean, median and std',meanRAdiff_twon, medianRAdiff_twon, stdRAdiff_twon) \n",
    "print('Dec difference mean, median and std',meanDecdiff_twon, medianDecdiff_twon, stdDecdiff_twon)\n",
    "print()\n",
    "print('Statistics on differences between RA and Dec in combined i2d file when run with tweakreg off')\n",
    "print('RA difference mean, median and std',meanRAdiff_twoff, medianRAdiff_twoff, stdRAdiff_twoff) \n",
    "print('Dec difference mean, median and std',meanDecdiff_twoff, medianDecdiff_twoff, stdDecdiff_twoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criteria for success.\n",
    "\n",
    "If the first set of images with no shift are well aligned as shown in images and the statistical comparison, that test passes.\n",
    "\n",
    "Once a shift is added, the statistics and number of sources found don't tell the whole story. Look at the combined images shown after image3 with and without tweakreg. If the image run with tweakreg shows double sources just like the image without tweakreg, then the test fails. If the image doesn't show double sources and looks like the unshifted combined image, then the test passes. Examine the image to look for obvious faults like stars that were not identified as stars, those with multiple star identifications, double star images, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About this Notebook\n",
    "\n",
    "Authors: M. Cracraft, M. Libralato and K. Gordon, MIRI Branch\n",
    "\n",
    "Updated On: 08/25/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
